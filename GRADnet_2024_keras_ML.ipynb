{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "u5tqTS9zK_mf",
        "1n0SYHxbLdg_",
        "PByfguajLvvb",
        "9w_bGso9Ncyv"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPAp7nDc6fqQFr9jgWEOlpC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TomStevo/GRADnetDMKeras2024/blob/main/GRADnet_2024_keras_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<table>\n",
        "  <tr>\n",
        "    <center>\n",
        "    <td bgcolor=\"FFFFFF\">\n",
        "      <img src=\"https://drive.google.com/uc?export=view&id=1FUSWDRDDflxrUrYBFPKHE50KrelBYO6N\" width = \"800\" >\n",
        "      </td>\n",
        "      <td>\n",
        "      <img  src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/34/University_of_Sussex_Logo.svg/1024px-University_of_Sussex_Logo.svg.png\" width = \"300\"\n",
        "      </td>\n",
        "      </center>\n",
        "    </tr>\n",
        "<table>  \n",
        "\n",
        "<!---weird that to put it in the middle I have to align it to the right-->"
      ],
      "metadata": {
        "id": "mWk_6sGEHNXz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dark matter: Searching for the invisible\n",
        "#Notebook Three: Using Machine Learning\n",
        "\n",
        "<font color=\"red\"> ***Instructions </font> :\n",
        "Go to File, Save as copy in Drive. Then you can name the file what you like, and you can edit this as you like its your copy with your code!***\n",
        "\n",
        "-> To run the code press play on the left. If you change the code, you MUST press play again to re run it.\n",
        "\n",
        "-> You need to play every section."
      ],
      "metadata": {
        "id": "TmISK3D8flWj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Before we start we need to setup the tensorflow decision forests package\n",
        "%pip install -U tensorflow_decision_forests"
      ],
      "metadata": {
        "id": "O6EVrjZXxRoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## About ##"
      ],
      "metadata": {
        "id": "PoLLKi9vYnWT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hello and welcome to this notebook where we are searching for dark matter in data collected by the ATLAS experiment. The ultimate goal is to create a tool to optimise the inputs of event features to automatically determine the signal from the background. We will create a type of **machine learning model** called a **binary classifier**. This will be trained to tell the difference between signal and background (thus being binary). Signal will be labelled with a **1** and background with a **0**.\n",
        "\n",
        "We use Machine Learning in ATLAS when searching for rare events and cut optimising does not give us a high enough significance (most amount of signal and smallest amount of background).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FLNiSyEDjGXe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1: Introduction##"
      ],
      "metadata": {
        "id": "Fd8JzN2jYALK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experimental particle physics involves a lot of data analysis. The LHC produces up to 1 billion proton-proton collisions per second. This results in a tremendous amount of data (around one petabyte per day, or $10^{6}$ gigabytes) which must be understood to find the underlying physics. Machine learning really benefits from this large amount of data allowing for effective models to be trained. The efficiency and speed of machine learning methods also results in a massive decrease in computing time compared with manual methods.\n",
        "At CERN, machine learning is used in many ways: for triggering, for event selection (what we shall be doing) and for particle and jet identification. See more on other uses [here](https://sparks.cern/ai-cern).\n",
        "\n"
      ],
      "metadata": {
        "id": "1GRtUdhGY3GA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook will be using the **python module keras** to create the classifiers. This machine learning module is robust enough for us to make full use of machine learning models but is still readable and simple to initialise. If you wish to learn about more advanced machine learning libraries, we recommend **PyTorch, TensorFlow, and especially the Keras documentation** (all python modules).\n",
        "\n",
        "We will also need NumPy, matplotlib and Pandas so we shall import these modules.\n",
        "\n",
        "Run the code below:\n"
      ],
      "metadata": {
        "id": "5nWBbNPXcirE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-sp0CTCutn8-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.axes as axes\n",
        "import ipywidgets as widgets #used to cread interactive elements within the notebook\n",
        "\n",
        "plt.style.use('seaborn-v0_8-deep') #plot styling"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will also set a seed for this project, so the results are reproduceable:"
      ],
      "metadata": {
        "id": "Dkw4wrc_5O01"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.random import seed\n",
        "#set seed value for all code\n",
        "seed_value = 420\n",
        "seed(seed_value)"
      ],
      "metadata": {
        "id": "3oIjDxNmt7jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2: What is machine learning? ##"
      ],
      "metadata": {
        "id": "hND7_sWPcftL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Machine learning (ML) is a field of **artificial intelligence**, which is the computing field of developing computer programs/algorithms that perform tasks that typically require human intelligence, such as problem-solving. This workbook will focus on **supervised learning**. This is when we train a machine learning model with example data of what we are looking for.\n",
        "\n",
        "**Example:** Let's say we want to teach a computer to recognise a dog in a picture. We will train the computer on lots of images of animals while telling the programme which images correspond to dogs. This will teach the computer to correctly recognise images of dogs.\n"
      ],
      "metadata": {
        "id": "UFt15aD-mDOp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1: General principles ###"
      ],
      "metadata": {
        "id": "oU_AdvBNnY4C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Machine learning models are computer algorithms that are trained to achieve specific goals without being programmed with explicit instructions on how to achieve them; they are not *programmed* but *trained*.\n",
        "\n",
        "There are two main tasks of machine learning:\n",
        "1.   **Regression:** The input is a set of multi-feature data points, and the output is a real number or a sequence of real numbers (e.g. inputs could be the features of a house and the output could be a predicted house price, [link](https://medium.com/codex/house-price-prediction-with-machine-learning-in-python-cf9df744f7ff)).\n",
        "2.   **Classification:** The input is a set of multi-feature data points and the output is an integer which represents different classes (e.g. based on what is contained within an email, a machine learning model could sort between mail and spam, [link](https://towardsdatascience.com/email-spam-detection-1-2-b0e06a5c0472)).\n",
        "\n",
        "In this notebook we shall be training a **classifier**.\n",
        "*   We will have <font color='#819468'>**objects**</font> which we are interested in.\n",
        "\n",
        "*   These objects need to be <font color='#688194'>**classified**</font> into a set number of groups.\n",
        "\n",
        "*   To do this the <font color='#946881'>**features**</font> of the objects are used.\n",
        "\n"
      ],
      "metadata": {
        "id": "KdiV81JaS38z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1.1: Pre-processing and notation ####"
      ],
      "metadata": {
        "id": "irq9heXGCbsj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before training our machine learning models we must prepare the data so the computer can make sense of it. We define a data set called $X$ which holds all the objects (with $x$ as a single object) and a $y$ data set which will hold all the labels that correspond to the objects (the $X$ data set).\n",
        "\n",
        "As well as doing this we will split the data up into two parts: training data and testing data. The purpose of these data sets is evident in their names. The classifier is trained on the training data then tested on the testing data - this is discussed further in Section 3.1 but the key point is that the testing data is new unseen data for the classifier to be tested on after training.\n"
      ],
      "metadata": {
        "id": "kKrZStrlCr-D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1.2: How does classification work? ####"
      ],
      "metadata": {
        "id": "21d7qGycrLWz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets take a step back from particle physics and consider different objects, lets say spherical fruit (e.g. apple, orange, tomato, etc.). We can identify the type of fruit using two features: colour and average radius. So we define an object as\n",
        "\n",
        "$x\\left (c, r  \\right )$.\n",
        "\n",
        "We want to create an algorithm that can classify these <font color='#819468'>objects</font> into two groups: lemons and everything else (e.g. grapes, oranges, apples, etc.). Lets say we have two <font color='#819468'>objects</font>:\n",
        "\n",
        "$x_{1}\\left (yellow, 2cm  \\right ) = \\text{a lemon}$,\n",
        "\n",
        "$x_{2}\\left (green, 8cm  \\right ) =  \\text{NOT a lemon (a watermelon)}$.\n",
        "\n",
        "We can plot these two points in a 2D graph with colour and radius as the dimensions:\n",
        "![MLd1_f](https://lh4.googleusercontent.com/-6YTfe0Nt1YOBBCb3-AreVNNjjyQeiSOlO0FZv_d8fPJC-VblzWN017DgcseX_DY8zE=w2400)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "H0dVJJoMrYM_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These points are the training data. The algorithm is explicitly told that these are, or are not, lemons, so it is using them to learn how to identify a lemon. Let's add more <font color='#819468'>objects</font> to train the algorithm:\n",
        "\n",
        "![MLd2_f](https://lh5.googleusercontent.com/bMdPJpENrYD1Zgs3zxv_7HtloOMb93eM8bS23THq-8jSFs655MEf_9qGoEF1UT9WXR0=w2400)"
      ],
      "metadata": {
        "id": "r6E8sZccdnuk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These <font color='#819468'>objects</font> make up the training data, The machine learning model uses them to\n",
        "find the boundaries of this plot to <font color='#688194'>classify</font> the two groups:\n",
        "\n",
        "![MLd3_f](https://lh3.googleusercontent.com/7YDZ5amhf3SvfRafzZN8GvKAKIkGTVF_9rHhOJRKJLjmsXB4PzikgC9_rReG2LpNtDc=w2400)"
      ],
      "metadata": {
        "id": "8mf3RNseduQy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then from these boundaries, the model can predict if a new <font color='#819468'>object</font> is a lemon or not a lemon by looking at where it is on the plot. So, let's introduce a new fruit that has not been seen. This is considered the testing data as it is unlabelled and was not seen by the machine learning model during training:\n",
        "\n",
        "![MLd4_f](https://lh5.googleusercontent.com/C-H8k2ctNTziBRKi4I3sUZbVJRbXwB3fE2bbHZWiNc_Fq2UDxDjGUquk5yMB35BLiuU=w2400)"
      ],
      "metadata": {
        "id": "wPdl9f4TfAPA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The machine learning algorithm doesn’t know what it is\n",
        "supposed to be, and has to use what it has learnt from the training data to\n",
        "guess if it is an orange or not. In this case, it would guess that the new fruit is not a lemon."
      ],
      "metadata": {
        "id": "q_yD_YXEimLw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obviously these two features are not enough to identify every type of fruit correctly. So, let's introduce more! Let's say we now have $N$ <font color='#946881'>features</font> (new features such as volume or colour brightness). Now our graph will be in $N$ dimensions. This is not plottable but the same logic as for 2-D is upheld:\n",
        "the machine learning model will find the part of this $N$-dimensional space (hyperspace) which belongs to lemons. It recognises complex pattens in the data.\n",
        "\n",
        "This is how machine learning models are trained to classify objects.\n"
      ],
      "metadata": {
        "id": "bv7nx4hMioJe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1.3: What is training? ####"
      ],
      "metadata": {
        "id": "-p4Ije04KalX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have been talking about training a lot, but what does it entail? In machine learning, we teach computer algorithms and test them to see how good they are at doing their job. We then give feedback to the algorithm which it uses to become more accurate. This process iterates until the algorithm can do its task to a set standard. Over time, the algorithm changes its logic to produce accurate results.\n"
      ],
      "metadata": {
        "id": "0kFb-IbkRENW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2: Our application ###"
      ],
      "metadata": {
        "id": "BlI1V_8gi5pG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So now our $N$ dimensions are the features of the collision events. We will train our classifier to recognise the complex patterns in the data to identify the signal events from the background ones."
      ],
      "metadata": {
        "id": "AozAArgKyua8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have objects:\n",
        "<font color='#819468'>\n",
        "*   **Collision events** from the Monte Carlo simulation (**1.2 million events**)\n",
        "</font>\n",
        "\n",
        "With the goal:\n",
        "<font color='#688194'>\n",
        "*   Classify **signal** from **background** (labelled as **1 or 0**)</font>\n",
        "\n",
        "To do this, we will use the features of the objects (**N = 7**):\n",
        "<font color='#946881'>\n",
        "*   **Leading lepton's transverse momentum**\n",
        "*   **Sub-leading lepton's transverse momentum**\n",
        "*   **Dilepton invariant mass** ($m_{ll}$)\n",
        "*   **Missing transverse energy** ($E_{Tmiss}$)\n",
        "*   **Angle between $E_{Tmiss}$ and net momentum of the dilepton** ($\\Delta \\phi$)\n",
        "*   **Fractional transverse momentum difference**\n",
        "*   **Missing transverse energy over total momentum** $E_{Tmiss}/H_T$\n",
        "</font>\n"
      ],
      "metadata": {
        "id": "2Zwt_62SjEyG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get the machine learning model to recognize the signal from background we shall train it on all the processes:"
      ],
      "metadata": {
        "id": "2xa89seooc67"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<table>\n",
        "<thead>\n",
        "<tr><th>Non-resonant lepton pair production</th><th>Z+ boson jets</th><th>W and Z boson production</th><th>Double Z boson production</th><th>Dark matter production</th></tr>\n",
        "</thead>\n",
        "</table>"
      ],
      "metadata": {
        "id": "j0LW7akNqXGO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets made an array to hold the names of the processes\n",
        "processes = ['Non-resonant_ll',\n",
        "              'Z+jets',\n",
        "              'WZ',\n",
        "              'ZZ',\n",
        "              'DM_300']"
      ],
      "metadata": {
        "id": "5abhEfMEuElN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As before we consider every process except dark matter production (DM 300) to be the background. Now let's load the data we need to do the analysis."
      ],
      "metadata": {
        "id": "HDtinYKX5uI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "All_processes_df = pd.DataFrame()\n",
        "\n",
        "index = 0\n",
        "\n",
        "for process in processes:\n",
        "  temp_df = pd.read_csv('https://gitlab.cern.ch/cyardley/opendatafordm/-/raw/master/DM_ML_notebook/'+process+'.csv')\n",
        "  temp_df[\"processID\"] = index\n",
        "  index = index + 1\n",
        "  temp_df['totalWeight'] = temp_df['totalWeight'].abs() # make negative weights positive for simplicity (not ideal)\n",
        "  All_processes_df = pd.concat([All_processes_df,temp_df],ignore_index=True)"
      ],
      "metadata": {
        "id": "WcMgg63HDEU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets set \"target\" *y* equal to 1 for the signal and 0 for all the backgrounds as a new column in the dataframe:"
      ],
      "metadata": {
        "id": "KKj6yoiMo1Pr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "All_processes_df[\"target\"] = np.where(All_processes_df['processID'] == 4, 1, 0)\n",
        "#print(All_processes_df)"
      ],
      "metadata": {
        "id": "7nj_g_iIE4a5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how many of each class there are:"
      ],
      "metadata": {
        "id": "PsARpt4NpFJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "All_processes_df['target'].value_counts()"
      ],
      "metadata": {
        "id": "UpnjOx_E7lfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can see from the output above that there are only 491 signal events but ~23000 background events. Below we replicate the signal a few times so there is a higher proportion of signal data to background data. This is so the models have more chance to recognise signal. This is a very rudimentary way of oversampling, which is a common technique for training ML models to recognise very rare events - for example, credit card fraud."
      ],
      "metadata": {
        "id": "CYnC7SVaojb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sig_temp = All_processes_df[All_processes_df['processID']==4] # Get just the signal events\n",
        "oversample_rate = 4.0 # set this here to adjust things later\n",
        "oversample = sig_temp.sample(frac=oversample_rate,replace=True) # Randomly sample them with replacement 4 times\n",
        "All_processes_df = pd.concat([All_processes_df,oversample],ignore_index=True) # Combine them back into the original dataframe"
      ],
      "metadata": {
        "id": "SYrMnTLIWx8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(oversample)\n",
        "All_processes_df['target'].value_counts()"
      ],
      "metadata": {
        "id": "zOf3eQFyYEbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have 5 times the number of signal events which will help with the training! This is a fairly crude method of increasing the training statistics and ideally we should get a bigger training sample by generating more Monte Carlo for example. We should also really take this into account later on when evaluating the performance."
      ],
      "metadata": {
        "id": "hFR0X1FIpuFv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have loaded the data let's go over the two types of classifiers we will be training."
      ],
      "metadata": {
        "id": "m-ZqFx4IDdnv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3: Random forest ###"
      ],
      "metadata": {
        "id": "6UZ9bp3JsPCE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first method we shall be going over is the **random forest**. This is a black box, ensemble learning method using **decision trees**. Now, there is a lot to unpack in that sentence but that is the technical description. This method works by creating a set number of [decision trees](https://www.youtube.com/watch?v=_L39rN6gz7Y) of a set depth - these are themselves machine learning models - then using them all in unison to make classifications.\n",
        "\n",
        "Decision trees are a structure of repeated binary cuts on individual variables in a flowchart like layout but instead of us defining the cuts, the model works out the most optimal cuts itself!.\n",
        "\n",
        "Cuts are made at decision nodes. Leaf nodes are where the cuts end and a classification is made. This is determined by a criterion that measures the quality of a cut. Examples include gini, entropy and log loss (read more about this in Section 2.3.1). The diagram below shows such a tree:\n"
      ],
      "metadata": {
        "id": "IFqIuUz8vmBZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Dtree](https://lh3.googleusercontent.com/93Lh9CaVLKpS2EYyOa-a5T5FZpRR2uMWqGiHeST_zbk3jA_JKynhxEi7eFhziW_9kOY=w2400)\n"
      ],
      "metadata": {
        "id": "_7buN8M0vrdz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model is optimised at each node to give the best separation of signal and background. They are very susceptible to overtraining (more on this later), but random forests overcome this.\n",
        "\n",
        "Each tree is trained using a random sample of $X$ with replacement (this is called **bootstrapping**) and a random selection of features to use for each tree (each tree can specialise). Each tree is then trained independently. Any new data point is passed through each tree to get different predictions. These predictions are combined to get a final one, this is called **aggregation**, and follows the same logic as \"wisdom of the crowd\".\n",
        "\n",
        "The diagram below shows the layout of a random forest made up of decision trees:\n",
        "![RF_DIA](https://lh3.googleusercontent.com/FzS39r5yR5K0daoJVKSj7eztT4btXsg2Owp5LRaXHrsPBxi_Qmhl_1adoINzrVtan9Y=w2400)\n",
        "\n",
        "\n",
        "Random forests have several **advantages**:\n",
        "* Overfitting is reduced due to ensemble learning, improving their accuracy;\n",
        "* Works well with both discrete and continuous variables;\n",
        "* Normally uneffected by outliers and missing values, which they can handle automatically;\n",
        "* The algorithm is very stable;\n",
        "* It is less affected by noise;\n",
        "* The feature importance can be identified.\n",
        "\n",
        "Yet, they also come with some **disadvantages**:\n",
        "* They require a large amount computational power resulting in longer training periods;\n",
        "* They have added complexity when lots of decision trees are trained.\n",
        "\n"
      ],
      "metadata": {
        "id": "YGijZGwvwUYB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.3.1: Advanced section: Gini, entropy and log loss\n",
        "\n",
        "**Read this section if you want to learn these more advanced topics! You can also skip this section, it wont be needed for the tasks later.** Click the arrow next to the section title to either show or to hide this section.\n"
      ],
      "metadata": {
        "id": "x-ihDfMuK547"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a nutshell, each of the three functions measure the quality of a cut in a decision tree, but in distinctly different ways. However, the exact mathematical formulations for each of them can be quite involved, even for regular users of machine learning. In the following, the interested reader may find rough descriptions, but you are encouraged to do any further reading yourself if you want more information.\n",
        "\n",
        "* **Gini impurity** measures the probability that data is mislabelled by the node as the incorrect class. If this probability is **0**, the node is pure (all data contained at the node are of the same class) and the decision tree will no longer split at that node. Under this method, the aim is for splits to be made which minimise gini impurity of nodes. More information may also be found [here](https://en.wikipedia.org/wiki/Decision_tree_learning).\n",
        "\n",
        "* **Entropy** calculates the disorder of features at a node. Similarly to gini impurity, the aim is for this to be minimised when a feature is used to split the data. Although it seems that gini and entropy are basically the same, more information can be found [here](https://quantdare.com/decision-trees-gini-vs-entropy/) which further outlines the subtle differences.\n",
        "\n",
        "* **Log loss** is a metric which is also sought to be minimised. The log loss is usually $-1 \\times log(L)$ where $L$ is something called a likelihood function. Liklihood functions provide a way to assess how well an observed outcome matches an expected one. In the context of decision trees, this is an assessment of how well the binary classification of a node corresponds to the actual makeup of data at that node. Further information can be found [here](https://towardsdatascience.com/intuition-behind-log-loss-score-4e0c9979680a) and [here](https://www.kaggle.com/code/dansbecker/what-is-log-loss/notebook).\n",
        "\n",
        "Further information on the three methods can also be found [here](https://scikit-learn.org/stable/modules/tree.html#tree-mathematical-formulation) and by a look at the variety of sources on the web. Yet, again, none of this information is needed to complete this workbook!!!"
      ],
      "metadata": {
        "id": "dQo-oKSxMVUE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.4: Neural network ###"
      ],
      "metadata": {
        "id": "4SWhmbU29KGR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The second method is the **neural network**, a mathematical function inspired by the biological neural networks of animal brains. It is made up of nodes/artificial neurons connected by weights. These weights signify the importance of each connection to make the correct prediction. Each neuron acts as a function by having a value dependent on those weights.\n",
        "\n",
        " Neural networks are constructed of layers of nodes:\n",
        "\n",
        "*   Input layer\n",
        "*   Hidden layers\n",
        "*   Output layer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HZVqXv_A9QlO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The input layer has a node for each dimension of the input. Here, these are the event features. Hidden layers exists which can be a varying size (the size is set before training and is called a hyperparameter) and there is an output layer made up of nodes which correspond to each classification group.\n",
        "\n",
        "The values of the input nodes correspond to the features of the objects to be identified and the output node vaules will correspond to what the object will be classified as.\n",
        "\n",
        "The diagram below shows the layout of a nodes and weights that make up a neural network:\n",
        "![NN_DIA](https://lh5.googleusercontent.com/L-bJ7gYuPDcO6lMqKg1LXx4inag-SR8afwMqnyfOZSKCKn3NBeUY7dEvS9MGar_hHnc=w2400)\n",
        "\n",
        "Again, as well as the advantages of machine learning as whole, neural networks have several other **advantages**:\n",
        "* Continuous Learning: a neural network can be trained continuously to improve its performance over time (it does not need to be retrained when training on more data);\n",
        "* They have a parallel processing capability;\n",
        "* There is an error tolerance due to the complexity of neurons;\n",
        "* Neural networks store the information of the data they are trained on\n",
        "* They are flexible.\n",
        "\n",
        "Yet, they also comes with some **disadvantages**:\n",
        "* Due to their parallel processing, they can be hardware dependant;\n",
        "* The algorithms can become very complex when used for specified tasks;\n",
        "* They have a black box nature: this means that the logic in which the neural network makes decisions is not understandable by humans due to its complexity;\n",
        "* The results are only approximations;\n",
        "* They are very dependent on the data: the whole nature of a neural network is dependent on the data it is trained on so erroneous data will, in turn, affect it.\n"
      ],
      "metadata": {
        "id": "zQMyVPB5bwZy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try experimenting with different layer sizes to see how the neural network is constructed. Run the hidden cell below this, then in the next cell set what parameters you want."
      ],
      "metadata": {
        "id": "6Gg6_jzcqzj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "def NeuralNetworkPlot(input_node_size,hidden_layer_sizes,output_node_size):\n",
        "\n",
        "    fig = plt.gcf()\n",
        "    ax = fig.gca()\n",
        "\n",
        "    scale = 0.2\n",
        "\n",
        "    layer_widths = [input_node_size]\n",
        "\n",
        "    for y in range(0,hidden_layer_sizes[1]):\n",
        "        layer_widths.append(hidden_layer_sizes[0])\n",
        "    layer_widths.append(output_node_size)\n",
        "\n",
        "    max_width = max(layer_widths)\n",
        "\n",
        "    buffer =  ( max_width - np.array(layer_widths) )/2\n",
        "    #print(buffer)\n",
        "    node_locations = []\n",
        "\n",
        "    for i,o in zip(layer_widths,buffer):\n",
        "        node_locations.append(np.linspace(0, i-1,i)+o)\n",
        "\n",
        "    to_be_plotted = 0\n",
        "\n",
        "\n",
        "\n",
        "    for i in range(0,len(node_locations)):\n",
        "        layer = node_locations[i]\n",
        "        if i == len(node_locations) -1:\n",
        "            break\n",
        "        next_layer = node_locations[i+1]\n",
        "        for o in range(0,len(layer)):\n",
        "\n",
        "            node = layer[o]\n",
        "            #print(node)\n",
        "            #print(\"=======\",i,i+1)\n",
        "            original = np.full(len(next_layer),node)\n",
        "\n",
        "            #print(original)\n",
        "\n",
        "            next_ = next_layer\n",
        "            #print(next_layer)\n",
        "            temp = np.c_[original,next_layer]\n",
        "\n",
        "            #print(\"=======\")\n",
        "\n",
        "            for u,p in zip(original,next_layer):\n",
        "                line = plt.Line2D([(i*scale),(i+1)*scale],[u*scale,p*scale],color = \"grey\", lw = 0.3)\n",
        "                plt.gca().add_line(line)\n",
        "\n",
        "            # for u in temp:\n",
        "            #     #print(i,i+1)\n",
        "            #     #print(u[0],u[1])\n",
        "\n",
        "            #     line = plt.Line2D([i,i+1],[u[0],u[1]])\n",
        "\n",
        "            #\n",
        "    for i in range(0,len(node_locations)):\n",
        "        layer = node_locations[i]\n",
        "        if i == 0:\n",
        "            colour = 'green'\n",
        "        elif i == len(node_locations)-1:\n",
        "            colour = 'red'\n",
        "        else:\n",
        "            colour = 'black'\n",
        "        plt.scatter(np.full(len(layer),i)*scale,layer*scale,zorder=10,color = colour,s=20/scale)\n",
        "\n",
        "\n",
        "            # circle1 = plt.Circle((i,layer[o]),0.1,color = 'r')\n",
        "\n",
        "            # ax.add_patch(circle1)\n",
        "\n",
        "\n",
        "    plt.xlim([-1*scale, (i+1)*scale])\n",
        "    plt.ylim([-1*scale, (max_width+3)*scale])\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.text((0-1)*scale,(max_width)*scale,\"Input layer\",color = 'green',fontsize = 20)\n",
        "    plt.text((0+1)*scale,(max_width)*scale,\"Hidden layers, \"+str(hidden_layer_sizes),fontsize = 20)\n",
        "    plt.text((len(layer_widths)-1)*scale,(max_width)*scale,\"Output Layer\",color='red',fontsize = 20)\n",
        "\n",
        "    plt.text((0.75)*scale,(max_width+2)*scale,\"Neural network diagram\",fontsize = 30)\n",
        "\n",
        "    fig.set_size_inches((max_width+3)*scale*10,(i+1)*scale*10)\n",
        "    #plt.savefig('myfigure_100.png', dpi=300)\n",
        "    plt.show()\n",
        "    #plt.rcParams[\"figure.figsize\"] = ((i+1),(max_width+1)*2)\n",
        "\n",
        "    #print(np.array(node_locations))\n",
        "\n",
        "#print(np.c_[np.array([1,1,1,1,1]),np.array([0,1,2,3,4])])"
      ],
      "metadata": {
        "id": "757Z-UsprVZ-",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Try out different sizes of layers\n",
        "NeuralNetworkPlot(7,(20,2),1)\n",
        "#                 ^input nodes\n",
        "#                     ^hidden nodes\n",
        "#                         ^output nodes"
      ],
      "metadata": {
        "id": "sQW9rRLa7yM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 2 quiz ###\n",
        "\n"
      ],
      "metadata": {
        "id": "JXGfFtWIPuv8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <font color=\"red\"> TASK </font> : Press play in the following code blocks and answer the questions!\n",
        "print(\"Which of the following is NOT a 'black box' machine learning model?\")\n",
        "out = widgets.Dropdown(options=[('',0),('Random forest',0),('Neural network',0),('Decision tree',1)],description='Answer:',disabled=False)\n",
        "def drop_check(guess):\n",
        "  if guess==1:\n",
        "    print(\"\\033[1;32;47m Correct!  \\n\")\n",
        "  else:\n",
        "    print(\"\\033[1;32;47m Incorrect.  \\n\")\n",
        "check = widgets.interactive_output(drop_check,{'guess':out})\n",
        "widgets.HBox([out,check])"
      ],
      "metadata": {
        "id": "2aB5_IBKjDVM",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Next Question\n",
        "print(\"In random forest machine learning models, how can I reduce overfitting?\")\n",
        "out = widgets.Dropdown(options=[('',0),('Increase each decision tree\\'s maximum depth',0),('Increase the number of decision trees in the forest',1),('Decrease the number of variables being used',0)],description='Answer:',disabled=False)\n",
        "def drop_check(guess):\n",
        "  if guess==1:\n",
        "    print(\"\\033[1;32;47m Correct!  \\n\")\n",
        "  else:\n",
        "    print(\"\\033[1;32;47m Incorrect.  \\n\")\n",
        "check = widgets.interactive_output(drop_check,{'guess':out})\n",
        "widgets.HBox([out,check])"
      ],
      "metadata": {
        "id": "yobrQJJ8j_7y",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Next Question\n",
        "print(\"I want to design a machine learning model which is\"+\n",
        "      \" capable of sorting 10,000 \\n images a day based on their\"+\n",
        "      \" average colour, average brightness, resolution in \\n DPI \"+\n",
        "      \"(dots per inch) and the number of red pixels contained \"+\n",
        "      \"within them. My \\n model would need to split the data into \"+\n",
        "      \"seven categories. How many dimensions \\n would I need to \"+\n",
        "      \"represent the data hyperspace?\")\n",
        "out = widgets.Dropdown(options=[('',0),('2',0),('4',1),('7',0),('10000',0)],description='Answer:',disabled=False)\n",
        "def drop_check(guess):\n",
        "  if guess==1:\n",
        "    print(\"\\033[1;32;47m Correct!  \\n\")\n",
        "  else:\n",
        "    print(\"\\033[1;32;47m Incorrect.  \\n\")\n",
        "check = widgets.interactive_output(drop_check,{'guess':out})\n",
        "widgets.HBox([out,check])"
      ],
      "metadata": {
        "id": "-WtJX0h8kcod",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Last Question\n",
        "print(\"You decide to train a neural network on your system which uses an Nvidia \\n\"+\n",
        "      \"graphics card. When you decide to switch to an identical system, except that \\n\"+\n",
        "      \"it uses an Intel graphics card, you find that the neural network no longer works \\n\"+\n",
        "      \"as expected. Why?\")\n",
        "out = widgets.Dropdown(options=[('',0),('Neural networks can be hardware dependent',1),('You can\\'t use neural networks on Intel graphics cards',0),('You made a programming mistake',0)],description='Answer:',disabled=False)\n",
        "def drop_check(guess):\n",
        "  if guess==1:\n",
        "    print(\"\\033[1;32;47m Correct!  \\n\")\n",
        "  else:\n",
        "    print(\"\\033[1;32;47m Incorrect.  \\n\")\n",
        "check = widgets.interactive_output(drop_check,{'guess':out})\n",
        "widgets.HBox([out,check])"
      ],
      "metadata": {
        "id": "mah7BUpNn_NC",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3: Application ##"
      ],
      "metadata": {
        "id": "xApG9bCEM6T0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now use these concepts to create two binary classifiers using a random forest and a neural network."
      ],
      "metadata": {
        "id": "UD79ri8uNJly"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1: Pre-processing ###"
      ],
      "metadata": {
        "id": "AxWQjDH-NPQm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As said in Section 2.2, we shall be using seven properties of  the collision events as the features *$X$* for the machine learning models:\n",
        "\n",
        "<table>\n",
        "<thead>\n",
        "<tr><th>Leading lepton's transverse momentum</th><th>Sub-leading lepton's transverse momentum</th><th>$m_{ll}$</th><th>$E_{Tmiss}$</th><th>$\\Delta{}\\phi{}$</th><th>Fractional transverse momentum difference</th><th>$E_{Tmiss}$/$H_T$</th></tr>\n",
        "</thead>\n",
        "</table>\n"
      ],
      "metadata": {
        "id": "axd5-wEO8RyD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also have some auxilary variables that we should keep track of like the processID, totalWeight and the target, some of which we need for the training and some we need later for the evaluation etc. totalWeight is the event weight  to account for the [selection effects](https://docs.google.com/document/d/1B_bzcKqTnBBZ-0K02aurW9o8FgfWlmEO-PxuP-f4ves/edit) of Monte Carlo generated data. Please keep an eye on where \"totalWeight\" makes appearances throughout this notebook, since this is used to properly scale our analysis and evaluation of the trained models.  "
      ],
      "metadata": {
        "id": "0A1nPCcsrF6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ML_inputs = ['lead_lep_pt',\n",
        "             'sublead_lep_pt',\n",
        "             'mll',\n",
        "             'ETmiss',\n",
        "             'ETmiss_over_HT',\n",
        "             'dphi_pTll_ETmiss',\n",
        "             'fractional_pT_difference']\n",
        "aux_variables = ['processID','totalWeight','target']"
      ],
      "metadata": {
        "id": "lRo_ABnLaLWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's have a look at some of the variables. First let's see how some of them look in 2D plots separately for the signal and background:"
      ],
      "metadata": {
        "id": "NXv58JvOuyzu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "sns.set_theme(style=\"ticks\")\n",
        "\n",
        "# get the signal and background events separately\n",
        "# from the dataframe based on the target\n",
        "sig = All_processes_df[(All_processes_df['target']==1)]\n",
        "bkg = All_processes_df[(All_processes_df['target']==0)]\n",
        "\n",
        "# define a helper function for the plotting\n",
        "def hex_plot(df,xvar,yvar,x_units,y_units):\n",
        "  ax = sns.jointplot(x=df[xvar].values,y=df[yvar].values, kind='hex')\n",
        "  xlab = xvar\n",
        "  ylab = yvar\n",
        "  if x_units != '':\n",
        "    xlab = xlab + ' [' + x_units + ']'\n",
        "  if y_units != '':\n",
        "    ylab = ylab + ' [' + y_units + ']'\n",
        "  ax.set_axis_labels(xlabel=xlab,ylabel=ylab)\n",
        "\n",
        "# plot some of the variables for the signal\n",
        "hex_plot(sig,'lead_lep_pt','ETmiss','GeV','GeV')"
      ],
      "metadata": {
        "id": "espIzUMsDkQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also look at the variables for both the signal and background together to see how the separation looks:"
      ],
      "metadata": {
        "id": "_FFbYgnuvSxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df = All_processes_df[ML_inputs]\n",
        "temp_df = pd.concat([temp_df,All_processes_df['target']],axis=1)\n",
        "g = sns.pairplot(temp_df, hue='target', markers='+')"
      ],
      "metadata": {
        "id": "DirdN8tRsKIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As said earlier before training our machine learning models, we must prepare the data so the computer can make sense of it. We start doing this by creating two data sets:"
      ],
      "metadata": {
        "id": "raiHJtyKNXLh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **$X$ data set**: this will hold all the input data for the machine learning model. This is done by selecting all the events from every process, then filtering the properties/features we want and combining them into a larger dataset. Note that the order of this data set is important.\n",
        "You may have noticed that we do this by selecting just the ***ML_inputs*** from the dataframe like ***All_processes_df[ML_inputs]***.\n",
        "\n"
      ],
      "metadata": {
        "id": "1F-5BcdUOT-L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **$y$ dataset**: this is a list of 1's and 0's corresponding to signal and background that lines up with the $X$ data set, where 1 denotes signal and 0 denotes background. Similarly to get the targets from the dataframe we do ***All_processes_df['target']***."
      ],
      "metadata": {
        "id": "0XKjc1OD8i2G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The diagram below shows the two data sets we have now created if each process has four data entries (obviously this is not actually the case):\n",
        "![data_diagram](https://lh3.googleusercontent.com/Q-oatcdBOqaxC4Oh7eIThv9VZCbySHq_xuUZjIrg46css0NTVqWUTvRw6BsHf8K8-f4=w2400)"
      ],
      "metadata": {
        "id": "xNQlEyD0taa_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In machine learning training, it is important to have training and testing sets of data.\n",
        "\n",
        "> Isn’t it the dream of every student to get very similar exam questions to ones they practiced with? It is easy to score well when you are familiarized with the problems being asked. To guarantee a fair test, teachers make sure to split their bank of questions into a training and a testing set. As such, students will have plenty to practice but still receive unseen questions on the test. The same applies to machine learning!\n",
        "\n",
        "If the machine learning model is trained on all the data, then tested on all the data the results will not give us any understanding on the effectiveness of the model as it is biased to test it on what it was trained with.\n",
        "\n",
        "To program this split of training and testing data, we shall simply feed in the dataframe into a function from the scikit-learn module that does it for us. Here, we will reserve a third of the data for testing with the remainder for training.\n"
      ],
      "metadata": {
        "id": "lnMHYZTR_3L1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#We shall be using scikit-learn to split the data into the training and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_df, test_df = train_test_split(All_processes_df, test_size = 0.33, random_state = seed_value)"
      ],
      "metadata": {
        "id": "CjdiUl4kM_LO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These data sets must now be **normalised**. This is important for the neural network model to converge. This is done again using **scikit-learn**.\n",
        "The importance of normalisation isn't obvious, but is needed. You may also think of it akin to standardisation, because it brings the mean average of data inputs close to some standard value (e.g. 0). This helps to speed up the optimisation of a neural network and reduce 'issues' along the way. These issues are intimately related to gradient descent (see Section 4.2.1) and the way in which a neural network is trained. For now, an analogy may be useful:\n",
        "\n",
        "> Let's say you are trained to work in a factory screwing various nuts and bolts into holes in pieces of furniture. If you are trained to work with nuts and bolts which are all of a similar size and weight, your musucle memory will help you to perform this task quicker; but if you are trained to work with nuts and bolts which vary irratically in this respect, it can be harder for you to optimise your way of working to easily complete your task. Thus, the factory decide to use a standard range of parts for you to use and you are happier.\n",
        "\n",
        "By standardising/normalising the inputs in machine learning, the machinary behind neural networks can behave in a more \"predictable\" way, thus improving the outcome.\n"
      ],
      "metadata": {
        "id": "Z2kv7XDeCCk5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<html>\n",
        "<details>\n",
        "<summary style=\"color:orange; font-weight: bold;\">For more information</summary>\n",
        "\n",
        "Please have a look\n",
        "[here](https://towardsdatascience.com/why-data-should-be-normalized-before-training-a-neural-network-c626b7f66c7d)\n",
        " [here](https://arxiv.org/pdf/1805.11604.pdf) and [here](https://medium.com/techspace-usict/normalization-techniques-in-deep-neural-networks-9121bf100d8)."
      ],
      "metadata": {
        "id": "_aUILvLwbOEw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below there are two variations of how to scale input variables:\n",
        "* [MinMax](https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.MinMaxScaler.html) scaling rescales the inputs between the specified range (-1 and +1 here),\n",
        "* [StandardScaler](https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.StandardScaler.html) gives the rescaled data each a mean of zero and unit standard deviation.\n",
        "\n",
        "The later isn't always appropriate especially if the variable does not follow a Gaussian distribution, which is the underlying assumption.\n",
        "\n",
        "Give both a go and see how the plots below look paying attention to the scale on the axes."
      ],
      "metadata": {
        "id": "_-xYpweByequ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scale = MinMaxScaler(feature_range=(-1,1))\n",
        "#from sklearn.preprocessing import StandardScaler\n",
        "#scale = StandardScaler()\n",
        "\n",
        "# \"fit\" the training dataset to get the scalings for the input variables\n",
        "scale.fit(train_df[ML_inputs].values)\n",
        "\n",
        "# apply the scaling to the training inputs to make a new scaled dataframe\n",
        "scaled_train_df = pd.DataFrame(scale.transform(train_df[ML_inputs].values),\n",
        "                               columns=ML_inputs,\n",
        "                               index=train_df.index)\n",
        "# attach the auxilary variables to the scaled training dataframe\n",
        "scaled_train_df[aux_variables] = train_df[aux_variables]\n",
        "\n",
        "# apply the scaling to the testing inputs to make a new scaled dataframe\n",
        "scaled_test_df = pd.DataFrame(scale.transform(test_df[ML_inputs].values),\n",
        "                               columns=ML_inputs,\n",
        "                               index=test_df.index)\n",
        "# attach the auxilary variables to the scaled testing dataframe\n",
        "scaled_test_df[aux_variables] = test_df[aux_variables]\n"
      ],
      "metadata": {
        "id": "vJRBYvVPQhHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can then look at the 2D plots again but for the scaled variables to see how they have changed:"
      ],
      "metadata": {
        "id": "MeK_D02q0Exe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#print(scaled_train_df)\n",
        "hex_plot(scaled_train_df[scaled_train_df['target']==1],'mll','dphi_pTll_ETmiss','GeV','')"
      ],
      "metadata": {
        "id": "LFrqMfhwR8Uz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now have the data prepared to train our machine learning models."
      ],
      "metadata": {
        "id": "vfsSK2gYCW9I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 3 : Quiz ###\n",
        "\n",
        "<font color=\"red\"> Quiz </font> : Play the following code blocks and answer the quiz :)"
      ],
      "metadata": {
        "id": "JYYYnX3LP3FF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "print(\"Why must there be independent training and testing datasets when developing machine learning models?\")\n",
        "out = widgets.Dropdown(options=[('',0),('To assess model accuracy',0),('To assess overfitting or underfitting',0),('Both',1)],description='Answer:',disabled=False)\n",
        "def drop_check(guess):\n",
        "  if guess==1:\n",
        "    print(\"\\033[1;32;47m Correct!  \\n\")\n",
        "  else:\n",
        "    print(\"\\033[1;32;47m Incorrect.  \\n\")\n",
        "check = widgets.interactive_output(drop_check,{'guess':out})\n",
        "widgets.HBox([out,check])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "lp8-WDV9pNzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "print(\"I decide to train a machine learning model to classify objects as \\\"round\\\" or \\\"not round\\\".\\n\"+\n",
        "      \"I choose to use two class labels: 0 and 1. If my objective is to select objects which are \\n\"+\n",
        "      \"\\\"round\\\" and to discard those which are \\\"not round\\\", does it matter which label I use for \\n\"+\n",
        "      \"which category?\")\n",
        "out = widgets.Dropdown(options=[('',0),('Yes',0),('No',1),('It depends',0)],description='Answer:',disabled=False)\n",
        "def drop_check(guess):\n",
        "  if guess==1:\n",
        "    print(\"\\033[1;32;47m Correct!  \\n\")\n",
        "  else:\n",
        "    print(\"\\033[1;32;47m Incorrect.  \\n\")\n",
        "check = widgets.interactive_output(drop_check,{'guess':out})\n",
        "widgets.HBox([out,check])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "B3w2rkVQpOqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4: Model training ##"
      ],
      "metadata": {
        "id": "gIjeN1y5Culv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Now that we understand and have prepared the data and features that we are using, we will now go through the process of training our machine learning models. As a reminder, training will involve teaching the algorithms with data which it will attempt to categorise between DM signal and background. As the data is labelled to indicate the \"true\" signal and background, this is **supervised learning** in which the labels provide feedback for how well the machine learning models are doing.  \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gw1rWFdjG_5s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1: Random forest (RF) ###\n",
        "\n",
        "**You can skip this Section 4.1 and go onto 4.2 if you are short on time, and return later!**\n",
        "If you want to skip, simply click on the arrow next to the section title to hide."
      ],
      "metadata": {
        "id": "W_TIRlJKCyNg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We shall start by training the random forest classifier. This is completed on a tree-by-tree basis. Each decision tree training is completed using the Gradient Boosted Trees (GBT) algorithm where a set of shallow trees are trained sequentially, then ensemble learning is used to make final predictions from all the separate tree predictions. To do this we will use the additional [tensorflow_decision_forests](https://www.tensorflow.org/decision_forests) package installed at the beginning."
      ],
      "metadata": {
        "id": "02GrIl-IHvEk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.1.2: Training the RF ####"
      ],
      "metadata": {
        "id": "sLO3m2uEKwsn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This module will give us the options to change the model’s hyperparameters before training:\n",
        "\n",
        "*   **max_depth** : The maximum depth of every decision tree.\n",
        "*   **num_trees** : The number of decision trees in the forest.\n",
        "*  **min_examples** : Minimum number of examples in a node.\n",
        "*   **subsample** : Ratio of the dataset (sampling without replacement) used to train individual trees for the random sampling method.\n",
        "*   **validation_ratio** : \tFraction of the training dataset used for validation if not validation dataset is provided.\n",
        "*   **random_seed** : Random seed for the training of the model. Learners are expected to be deterministic by the random seed.\n",
        "*   **shrinkage** : Coefficient applied to each tree prediction. A small value (0.02) tends to give more accurate results (assuming enough trees are trained), but results in larger models. Analogous to neural network learning rate. Default: 0.1."
      ],
      "metadata": {
        "id": "prfqsVzqLpNV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Many more are available and can be found in the [GradientBoostedTreesModel](https://www.tensorflow.org/decision_forests/api_docs/python/tfdf/keras/GradientBoostedTreesModel) documentation."
      ],
      "metadata": {
        "id": "9CMOd-Wj65mE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's train the random forest classifer with these hyperparameters:"
      ],
      "metadata": {
        "id": "CvWkleXyW4kc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "import tensorflow_decision_forests as tfdf\n",
        "keras.utils.set_random_seed(seed_value)"
      ],
      "metadata": {
        "id": "Z0MWLMbKwXZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we need to collect the inputs and make them *features*:"
      ],
      "metadata": {
        "id": "DcZOtdWLITH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_features = []\n",
        "for input in ML_inputs:\n",
        "  training_features.append(tfdf.keras.FeatureUsage(name=input))"
      ],
      "metadata": {
        "id": "9VCc9limHvOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the model with the various training parameters:"
      ],
      "metadata": {
        "id": "byqgapAG7KeA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GBT_model = tfdf.keras.GradientBoostedTreesModel(\n",
        "      verbose = 1,\n",
        "      features = training_features,\n",
        "      exclude_non_specified_features = True, # this is needed so only the specified variables are considered\n",
        "      num_trees = 150,\n",
        "      max_depth = 2,\n",
        "      min_examples = 6,\n",
        "      subsample = 0.65,\n",
        "      validation_ratio=0.1,\n",
        "      task=tfdf.keras.Task.CLASSIFICATION,\n",
        "      random_seed = seed_value,\n",
        "      shrinkage = 0.2,\n",
        ")"
      ],
      "metadata": {
        "id": "lzQVcdg3w0hH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we need to ocompile the model and we can specify metrics we want to evaluate the training with:"
      ],
      "metadata": {
        "id": "jKmyHJb77Oxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GBT_model.compile(metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "LDywElIW4NJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's train the model! (Note: we convert to a tf dataset here for convenience)"
      ],
      "metadata": {
        "id": "clalbyNm7yo8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(scaled_train_df,label='target',weight='totalWeight')\n",
        "GBT_model.fit(train_ds)"
      ],
      "metadata": {
        "id": "zA1qPy5O4Ost"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take a look at a summary of the trained model:"
      ],
      "metadata": {
        "id": "HQV9Tjre8u7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GBT_model.summary()"
      ],
      "metadata": {
        "id": "XC_enr7gyrO6",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It gives details about the training as well as how important the inputs are and how often they appear in the different nodes of the network.\n",
        "\n",
        "We can also look at individual trees:"
      ],
      "metadata": {
        "id": "bCd5g61i92nm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfdf.model_plotter.plot_model_in_colab(GBT_model, tree_idx=20, max_depth=3)"
      ],
      "metadata": {
        "id": "Klj2fr7G-Hcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(scaled_test_df,label='target')\n",
        "evaluation = GBT_model.evaluate(test_ds, return_dict=True)"
      ],
      "metadata": {
        "id": "kV1I1Kx13MuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2: Neural network (NN) ###"
      ],
      "metadata": {
        "id": "blP2MrdtGRrT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will be training the **neural network classifier**.\n",
        "\n",
        "To begin, the neural network is **randomly seeded**, then something called the **loss function** is calculated by comparing predictions (on the training data) to the expected values.\n",
        "\n",
        "The loss function is essentially a measurement of how **inaccurate** the neural network's predictions are - the smaller the loss function, the better the neural network.\n",
        "\n",
        "Next, we perform something called **gradient descent** to minimise this loss function which is done through backpropagation - adjustment of weights for each neuron, layer-by-layer, to improve the prediction.\n",
        "\n",
        "**You may read more about the training in the next advanced section however, it is not necessary to continue the notebook** (and will not be in the quiz).\n"
      ],
      "metadata": {
        "id": "qcf2f1vEYaEY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.2.1: Advanced section: NN training####"
      ],
      "metadata": {
        "id": "Bd0W0i3kGkst"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient descent is a technique by which we can find a local minimum or maximum of any function, without having to solve it. We use it to find the minimum of the loss function, so that the neural network's predictions are as good as possible. [This video](https://youtu.be/fXQXE96r4AY) explains it more fully.\n",
        "\n",
        "\"Gradient descent is an iterative operation which seeks to find local minima or maxima of a function\" is how it's generally defined, but this is vague and difficult to understand intuitively. Instead, it may be more convenient to use an analogy: gradient descent is analogous to the whole process of hiking down the mountain and it is related to the steepness of the loss function. In more technical terms, it is the iterative process of calculating the current value of the loss function (scouting) and then altering the inner parameters of the NN by a step down in the loss function (stepping). The NN repeats this process through multiple iterations, each time decreasing the step size (field of view decreases) until it reaches a model optimized for successfully classifying signal and background events (a city is reached).\n",
        "\n",
        "In the animation below, the black dot represents the position of a neural network as it descends along the gradient by a definite step size. Just like you might see in a topographic map, the gradient of the loss function is colour-coded in a mesh where red are the peaks and blue are the valleys. Note how the descent slows down as the gradient flattens. Did your hiking adventure look like that?\n",
        "\n",
        "![Gradient Descent Diagram](https://drive.google.com/uc?export=view&id=1YeUNA9oDVNyPxX_Re1lIx1Z3ZIBm24Nv)\n",
        "\n",
        "You may recall that the normalisation is linked with gradient descent. In more precise language, normalisation/standardisation is done to make the gradient descent optimisation work faster. If data is not normalised, there is the chance that gradient descent is less likely to converge to a solution for a loss function (e.g. you are hiking along a \"mountain\" which looks rather flat for miles and miles around and are unable to easily see a path to the lowest point; or you are hiking over such a small mound of a mountain - say an anthill - that your stride is great enough that you step right over the mound without seeing it!!)."
      ],
      "metadata": {
        "id": "-bNyMD-tGnAD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.2.2: Training the NN ####"
      ],
      "metadata": {
        "id": "iW6mXh3xGn7y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We shall also be training the neural network using keras. For this we will be using the Sequential model which is a set of layers where each one has one input tensor and one output tensor that are then chained together.\n",
        "\n",
        "Again, we have the option to change the model’s hyperparameters before training:\n",
        "\n",
        "* Layers :\n",
        "  * [Input](https://keras.io/api/layers/core_layers/input/) : Special layer to specify input *shape*.\n",
        "  * [Dense](https://keras.io/api/layers/core_layers/dense/) : Performs the operation *output = activation(dot(input, kernel) + bias)* where activation is the activation function, kernel is a weights matrix created by the layer, and bias is a bias vector created by the layer:\n",
        "    * units : Positive integer for the number of nodes in the layer\n",
        "    * [activation](https://keras.io/api/layers/activations/) : Activation function to use\n",
        "* [Loss](https://keras.io/api/losses/) : function to minimise during training.\n",
        "* [Optimizer](https://keras.io/api/optimizers/) : optimisation (gradient descent) method.\n",
        "* batch_size : Number of samples per gradient update.\n",
        "* epochs : Number of iterations over the entire dataset.\n",
        "\n",
        "**Note that this is not all the options and you should look in the documentation for what else can be configured!**\n",
        "\n"
      ],
      "metadata": {
        "id": "CzzNwo8XGyPC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's train the neural network classifer with these hyperparameters:"
      ],
      "metadata": {
        "id": "cAZYcx8MSsLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import Sequential\n",
        "from keras.layers import Input,Dense\n",
        "from keras.utils import plot_model\n",
        "NN_model = Sequential()\n",
        "NN_model.add(Input(shape=(len(ML_inputs),)))\n",
        "NN_model.add(Dense(20, activation='relu'))\n",
        "NN_model.add(Dense(20, activation='relu'))\n",
        "NN_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "opt = keras.optimizers.Adam(learning_rate=0.005)\n",
        "\n",
        "NN_model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "x_-L6hA12efX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the model is compiled we can get a summary of the configuration:"
      ],
      "metadata": {
        "id": "9b2GsA3uQL23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NN_model.summary()\n",
        "#plot_model(model,show_shapes=True,show_dtype=True,show_layer_activations=True)"
      ],
      "metadata": {
        "id": "w6RdD1FoQGly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And now for the training!"
      ],
      "metadata": {
        "id": "5R6LhHvTQUUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NN_model.fit(x=scaled_train_df[ML_inputs],y=scaled_train_df['target'],batch_size=32, epochs=10)"
      ],
      "metadata": {
        "id": "RYK9by1ndkFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = NN_model.evaluate(scaled_test_df[ML_inputs],scaled_test_df['target'])"
      ],
      "metadata": {
        "id": "biUKqwrwgLC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = pd.DataFrame()\n",
        "predictions = pd.concat([predictions,scaled_test_df['target']],axis=1)\n",
        "predictions['pred'] = NN_model.predict(scaled_test_df[ML_inputs])"
      ],
      "metadata": {
        "id": "APzRpAT0h_fr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(predictions)"
      ],
      "metadata": {
        "id": "6ZXAHtbTMlBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3: Prediction sneak peek ###"
      ],
      "metadata": {
        "id": "sBnYtd9hNtfO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have trained the classifiers, lets briefly experiment with prediction. First of all, we will pick a random event object from the test data set and see if it is signal or background:"
      ],
      "metadata": {
        "id": "xO-Dh1vTODSO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get a random event from the test dataset\n",
        "event_object = predictions.sample(1)\n",
        "print(event_object)"
      ],
      "metadata": {
        "id": "XHUCrdGA1uPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So now we know what this event is actually classified as, let’s see if the classifiers correctly predict what this event is (signal or background). We can do this using the predict( 𝑋 ) method in scikit-learn, this returns the predicted class of an input sample.\n",
        "This class prediction is found from the prediction probabilities of being signal and of being background. We can get these probabilities by using the **predict_log_proba($X$)** method in scikit-learn which acts on the classifier:"
      ],
      "metadata": {
        "id": "Oz5H23iQ9hIy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This method returns two probabilities in an array with index 0 holding the background probability and index 1 holding the signal probability. We are most interested in the probability of an event being signal. These probabilities are much more use to us then just the class label as we can study the range of probabilities to understand how our classifiers are working.\n",
        "\n",
        "In the next section we will look at these predicted probabilities (also considered the response of the machine learning model) for the whole test data set  𝑋 . We will see that the full responses produce distributions which can be analysed, like what was done in notebook 2."
      ],
      "metadata": {
        "id": "L_MX0v2E9q8p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 4 Quiz ###"
      ],
      "metadata": {
        "id": "ssBQUK8BP6Gl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "print(\"When training a neural network, how does it optimise itself?\")\n",
        "out = widgets.Dropdown(options=[('',0),('By maximising a \"gain\" function',0),\n",
        "                                ('By stabilising an output',0),\n",
        "                                ('By minimising a \"loss\" function',1)],description='Answer:',disabled=False)\n",
        "def drop_check(guess):\n",
        "  if guess==1:\n",
        "    print(\"\\033[1;32;47m Correct!  \\n\")\n",
        "  else:\n",
        "    print(\"\\033[1;32;47m Incorrect.  \\n\")\n",
        "check = widgets.interactive_output(drop_check,{'guess':out})\n",
        "widgets.HBox([out,check])"
      ],
      "metadata": {
        "id": "tHbsOXjSrS0c",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "print(\"Which of the following is NOT a hyperparameter of a neural network?\")\n",
        "out = widgets.Dropdown(options=[('',0),('Hidden layer sizes',0),\n",
        "                                ('Verbose',1),\n",
        "                                ('Activation',0)],description='Answer:',disabled=False)\n",
        "def drop_check(guess):\n",
        "  if guess==1:\n",
        "    print(\"\\033[1;32;47m Correct!  \\n\")\n",
        "  else:\n",
        "    print(\"\\033[1;32;47m Incorrect.  \\n\")\n",
        "check = widgets.interactive_output(drop_check,{'guess':out})\n",
        "widgets.HBox([out,check])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "P883x5-xrTfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "print(\"In training the random forest, which of the following hyperparameters was responsible \\n\"+\n",
        "      \"for each decision tree being trained on a random sample of the training data with replacement?\")\n",
        "out = widgets.Dropdown(options=[('',0),('Random state',0),\n",
        "                                ('Bootstrap',1),\n",
        "                                ('No. of estimators',0)],description='Answer:',disabled=False)\n",
        "def drop_check(guess):\n",
        "  if guess==1:\n",
        "    print(\"\\033[1;32;47m Correct!  \\n\")\n",
        "  else:\n",
        "    print(\"\\033[1;32;47m Incorrect.  \\n\")\n",
        "check = widgets.interactive_output(drop_check,{'guess':out})\n",
        "widgets.HBox([out,check])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "xjOLW9e_rTuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5: Prediction and model evaluation ##"
      ],
      "metadata": {
        "id": "BQC1qr0LOezA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have trained the classifiers, we can use them to predict if an event is background or signal.\n",
        "\n",
        "We must also evaluate these models to understand how well they are working and give us the chance to optimise the machine learning models' responses. We will perfect the classifiers using the Monte Carlo data, then we will be able to use it in practice with real experimental data.\n",
        "\n"
      ],
      "metadata": {
        "id": "YHtRi47c1HSG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1: Model analysis ###"
      ],
      "metadata": {
        "id": "9lWcwFXK6eRn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analysis methods include:\n",
        "*   Plotting ML model response for signal and background\n",
        "*   ROC curve\n",
        "*   Overfitting check\n",
        "*   KS test\n",
        "\n",
        "This section will go through these methods, and you will be given a chance to optimise the classifiers for the best and most accurate prediction.\n"
      ],
      "metadata": {
        "id": "zukQpRtJ62WQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.1.1: Model response ####"
      ],
      "metadata": {
        "id": "EUgoBYvT4Iz3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking at the response of the classifiers using the test data we see how the model is responding to the signal and background differently. As was said in Section 4.3, we will look at the predictions for the whole $X$ test data set. When we do this, we will see a distribution of responses over the whole data set. The goal for the coming sections will be to optimise this response to clearly see two distributions in this data - one for signal and one for background. This indicates new physics.\n",
        "\n",
        "How would we plot this? If we take the $x$-axis of a plot to be the predicted probability that an object is signal, then we plotted all the objects in a sample as two separate histograms (one for signal labelled objects and one for background labelled) on the same axis, we can see the distributions. We can do this as we know beforehand which events are background and signal (the $X$ test set corresponds with $y$ test labels). Note this would not be possible with real, non-Monte Carlo data as it is unlabelled.\n",
        "\n",
        "Let’s consider a perfect classifier, the plot would look like:\n",
        "\n"
      ],
      "metadata": {
        "id": "cCI4Z1Pi7BDK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![out_1](https://lh6.googleusercontent.com/TiZwRuPDGvuDb6jZ2H2ymbyplcCBr1DCs-f45ufKFroxFpsxUUqXRymtXPJ-ezYyddU=w2400)"
      ],
      "metadata": {
        "id": "crt8T3CsK3Hy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In reality the classifier, is not perfect, but a strong separation of signal from the background could look like this:\n",
        "![output_2](https://lh5.googleusercontent.com/Vfn64iGQDJVxQvFFQEkol-DGgCGUQGLyWIfk7GLcOdTShAFTO8xef1ZkTgOLpwp9wGs=w2400)"
      ],
      "metadata": {
        "id": "BGBnjY9oOqtg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A real example of this from the ATLAS experiment can be seen below. This shows two clear distributions for the total background (blue) and the Higgs signal (dotted red). NOTE: the horizontal axis here is NN output not the prediction, but generally these can be considered as the same (just with a different horizontal axis range). The Higgs signal considered here is a rather specific process which (crucially) involves a Higgs boson.\n",
        "\n",
        "![atlasNNoutput](https://lh5.googleusercontent.com/9J_6RG1mf8jIg5Uy2J4zVTmvTXqZE-0jHz4KO0OV9jne3Rl93HbSdUEpNg9srK74yrc=w2400)\n",
        "\n",
        "The two distributions clearly show different trends in how the neural network responds, suggesting it is a useful NN for isolating a signal. This neural network was developed in work which sought to find evidence of a Higgs boson by isolating the signal for this specific Higgs process. This graph shows that a cut (more in Section 5.2) on the NN output between $0.0$ and $0.5$ could strongly select for the Higgs process. We will be looking to use our ML models in a similar way to find dark matter!!\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AVD5JgKrPTEw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let’s plot the response of our classifiers. We will plot two histograms - orange for signal and blue for background. While the $y$-axis of response plots can be expressed using a variety of units, the plots we will be creating will be histograms for the **frequency** with which the classifier outputs some signal probability between $0$ and $1$. We shall write a function to plot the output of any classifier for the $X$ data we give it:"
      ],
      "metadata": {
        "id": "w2Xehz9YPa7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get predictions from the GBT\n",
        "scaled_test_df[\"GBT_preds\"] = GBT_model.predict(test_ds)\n",
        "scaled_train_df[\"GBT_preds\"] = GBT_model.predict(train_ds)\n",
        "# get predictions from the NN\n",
        "scaled_test_df[\"NN_preds\"] = NN_model.predict(scaled_test_df[ML_inputs])\n",
        "scaled_train_df[\"NN_preds\"] = NN_model.predict(scaled_train_df[ML_inputs])\n",
        "print(scaled_test_df)"
      ],
      "metadata": {
        "id": "Js0-AJ8BjYgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BINS = 20\n",
        "\n",
        "def plot_response(df,Title,preds,n_bins,Log):\n",
        "    \"\"\"\n",
        "    This function plots the response of a classifer on signal and background\n",
        "    Monte Carlo events\n",
        "\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    fig : TYPE\n",
        "        DESCRIPTION.\n",
        "    clf : TYPE\n",
        "        DESCRIPTION.\n",
        "    Title : TYPE\n",
        "        DESCRIPTION.\n",
        "    sig : TYPE\n",
        "        DESCRIPTION.\n",
        "    sig_weights : TYPE\n",
        "        DESCRIPTION.\n",
        "    bkg : TYPE\n",
        "        DESCRIPTION.\n",
        "    bkg_weights : TYPE\n",
        "        DESCRIPTION.\n",
        "    n_bins : TYPE\n",
        "        DESCRIPTION.\n",
        "    index : TYPE\n",
        "        DESCRIPTION.\n",
        "    xAxis : TYPE\n",
        "        DESCRIPTION.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    None.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    sig = df[df['target']==1]\n",
        "    bkg = df[df['target']==0]\n",
        "\n",
        "    # Get response (in form of probabilities) of signal and background\n",
        "    sig_prob = sig[preds].values\n",
        "    bkg_prob = bkg[preds].values\n",
        "\n",
        "    sig_weights = sig['totalWeight'].values\n",
        "    bkg_weights = bkg['totalWeight'].values\n",
        "\n",
        "    # find min and max for plot\n",
        "    d_min = min(sig_prob.min(), bkg_prob.min())\n",
        "    d_max = max(sig_prob.max(), bkg_prob.max())\n",
        "\n",
        "    # plot background response (make orange and translucent)\n",
        "    plt.hist(bkg_prob,\n",
        "             bins = n_bins,\n",
        "             range = (d_min,d_max),\n",
        "             color = 'tab:blue',\n",
        "             label = 'bkg test',\n",
        "             alpha = 0.4,\n",
        "             density = False,\n",
        "             weights = bkg_weights,\n",
        "             log = Log,\n",
        "             histtype=\"stepfilled\",\n",
        "             edgecolor='tab:blue',\n",
        "             linewidth=5)\n",
        "\n",
        "\n",
        "    # plot signal response (make blue and translucent)\n",
        "    plt.hist(sig_prob,\n",
        "             bins = n_bins,\n",
        "             range = (d_min,d_max),\n",
        "             color = 'tab:orange',\n",
        "             label = 'sig test',\n",
        "             alpha = 0.4,\n",
        "             density = False,\n",
        "             weights = sig_weights,\n",
        "             log = Log,\n",
        "             histtype = \"stepfilled\",\n",
        "             edgecolor ='tab:orange',\n",
        "             linewidth = 5)\n",
        "\n",
        "    # Set up plot\n",
        "    plt.title(Title)\n",
        "    plt.xlabel(\"Response (0 = background, 1 = signal)\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.legend()\n",
        "    fig = plt.gcf()\n",
        "    fig.set_size_inches(12, 6)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "    return"
      ],
      "metadata": {
        "id": "rGcBd8-YjaOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To call this function properly, we must sort the $X$ test and training data into background and signal data sets; further, we must sort the $X$ data's **weights** too (remember that since the data here are Monte Carlo, we MUST use the weights to **rescale** the data so that we can plot the frequencies as if they were real data):"
      ],
      "metadata": {
        "id": "m1gaPD1D-BTx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's call the function and plot the response of the classifers, first for the random forest:"
      ],
      "metadata": {
        "id": "JtqkNr0K-G3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_response(scaled_test_df,\"GBT\",\"GBT_preds\",BINS,False)"
      ],
      "metadata": {
        "id": "oFJ3q8E3jmJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is hard to see the signal as dark matter is such a rare process. So let's set the $y$-axis to logarithmic scaling:"
      ],
      "metadata": {
        "id": "5tRgyItu-Lt-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_response(scaled_test_df,\"GBT\",\"GBT_preds\",BINS,True)"
      ],
      "metadata": {
        "id": "EO_8X66a-Wnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "That is much better - we can see the distributions. Now let's do the same for the neural network:"
      ],
      "metadata": {
        "id": "OQt016_O-Pi_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_response(scaled_test_df,\"NN\",\"NN_preds\",BINS,True)"
      ],
      "metadata": {
        "id": "9KsxBn3t-R3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "At the start of Section 5.1.1, we outlined some general, if optimisitic, response plots which showed a good degree of separation between some background and some signal. In contrast, the plots which we have produced show a less distinct separation between DM signal and background in the MC data. This doesn't mean that the neural network or random forest are not doing anything to classify the data. Rather it is simply because we are trying to find a very tricky DM signal (which remember is similar enough to our background such that a cut-based optimisation is not enough).\n",
        "\n",
        "Instead, we see that the background and signal responses follow different responses;\n",
        "\n",
        "* For the random forest, the response is rather uniform for the signal data, whereas the background response is peaks towards $0.00$ and decreases for higher probabilities;\n",
        "\n",
        "* For the neural network, the signal response is less uniform than for the neural network but is spread out over a larger range than the random forest; the background response peaks towards $0.00$ and decreases rapidly.\n",
        "\n",
        "From our intermediate results, you may be able to make a guess as to which machine learning model produces a better separation between background and signal - neural network or random forest?"
      ],
      "metadata": {
        "id": "wiJj-3YtY9nY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  5.1.2: ROC curve ####\n"
      ],
      "metadata": {
        "id": "hh3FVV6r4Zvz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To understand how well the machine learning model is working, we can look at the ROC curve. To do this, let's first introduce some new metrics: <font color='green'>TP</font> (number of true positives), <font color='red'>FN</font> (number of false negatives), <font color='red'>FP</font> (number false positives) and <font color='green'>TN</font> (number of true negatives). These are defined as the following:\n",
        "\n",
        "*   TP: Signal events correctly identified as signal events;\n",
        "*   FN: Signal events incorrectly identified as background events;\n",
        "*   FP: Background events incorrectly identified as signal events;\n",
        "*   TN: Background events correctly identified as background events.\n",
        "\n",
        "As you may have realised in this case, a background event is considered negative while a signal event is considered positive.\n",
        "\n",
        "The box in the image below shows the definition of these metrics. The columns divide objects predicted as signal (left) and background (right) while the rows divide objects that are actually signal (top) and background (bottom).\n",
        "\n",
        "From these metrics we can construct two values to describe the effectiveness of our classifiers: true positive rate and false positive rate. Below these values are explained:"
      ],
      "metadata": {
        "id": "0doLc_Pe7Zle"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![ROC](https://lh4.googleusercontent.com/dRQIT12SO5RR4paENExHGImZuJXMV49OR6Ezk8NtmclBLDnmJUBdLmlnq9fIr-d45eg=w2400)"
      ],
      "metadata": {
        "id": "EKtj2_5T9IYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "y_target = scaled_test_df['target'].values\n",
        "y_preds_GBT = np.where(scaled_test_df['GBT_preds'] > 0.5, 1, 0)\n",
        "conf_mat = confusion_matrix(y_target, y_preds_GBT)\n",
        "print(conf_mat)\n",
        "# Confusion matrix format: [[tn fp][fn tp]]\n",
        "# We will come back to this later"
      ],
      "metadata": {
        "id": "bR-HZhtuINOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have these two values we can optimize them for the best classification. Let’s think back to Section 5.1.1 where we plotted the response of our models in the form of two histograms on the same plot to show the distributions."
      ],
      "metadata": {
        "id": "AVrt5U8R9nbw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consider a vertical line on the histogram that represents a threshold. Everything to the right of that vertical line is now classified as a signal event, and everything to the left a background event. We can move this line to the left or right in turn changing the threshold. Doing this changes the TP, FN, FP and TN numbers and thus in turn changes the TPR and FPR. If we change this threshold from 0 to 1 (going from left to right) we can plot TPR and FPR as they change. This plot is called the 'receiver operating characteristic' (ROC) curve. With TPR as the $y$-axis and FPR as the $x$-axis, the plot below shows (as well as other lines) an example of a neural networks ROC curve (blue line):"
      ],
      "metadata": {
        "id": "ypZcqiLmBq-B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![rocCurve](https://lh6.googleusercontent.com/1hC1foz56Jr5pLrluF0sRyaOKR5Nr0Oj0mgd-8ls2OMOHCESigFL7DcK9paD888yScQ=w2400)"
      ],
      "metadata": {
        "id": "G1W3WDHVAGSW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   **Perfect classifier** : A perfect classifier will 100% correctly classify signal from background;\n",
        "*   **Random classifier** : A random classifier will randomly classify signal form background;\n",
        "*   **NN classifier** : An example of a decent classifier.\n",
        "\n",
        "The goal is to minimise FPR and maximise TPR, or in other words, to get the curve as close as possible to the top left hand corner.\n"
      ],
      "metadata": {
        "id": "P2BNA47EFclH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let’s plot the ROC curves for both our classifiers. Luckily for us, scikit-learn has a built-in function that does this for us. The **roc_curve** function takes in the $y$ test data, the array of thresholds (classifier response probabilities) and outputs corresponding FPRs and TPRs:"
      ],
      "metadata": {
        "id": "hFlitwJ3HDC_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s now define a function to plot the ROC curve for both a classifer and a random classifier:"
      ],
      "metadata": {
        "id": "hgaVKyjr-l3x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the needed modules to analyse the classifers\n",
        "from sklearn.metrics import accuracy_score, roc_curve, roc_auc_score\n",
        "\n",
        "def calc_roc(y,\n",
        "             y_pred,\n",
        "             weights,\n",
        "             Title):\n",
        "    \"\"\"\n",
        "    This function calculates the ROC curve for a given classifer then plots it.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Get the prediction of the classifer\n",
        "    #y_prob = clf.predict_proba(X)[:,1]\n",
        "\n",
        "    # Use the scikit-learn function to calulate the FPR and TPR vaules corresponding\n",
        "    # to the therssholds. The line after that finds the area under the ROC curve\n",
        "    fpr, tpr, thresholds = roc_curve(y ,y_pred, sample_weight = weights)\n",
        "    roc_auc = roc_auc_score(y ,y_pred,labels=[0,1])\n",
        "    #roc_auc = 1\n",
        "\n",
        "    # set up the plot\n",
        "    plt.figure()\n",
        "    plt.plot(fpr,tpr,color='tab:orange', lw=2, label='ROC Curve (area = %0.2f)'%roc_auc)\n",
        "    plt.plot([1,0],[1,0], color='tab:blue', lw=2, linestyle='--', label='Random classifier')\n",
        "    plt.xlim([0.0,1.0])\n",
        "    plt.ylim([0.0,1.05])\n",
        "    plt.xlabel('FPR')\n",
        "    plt.ylabel('TPR')\n",
        "    plt.title(Title)\n",
        "    plt.legend()\n",
        "    fig = plt.gcf()\n",
        "    fig.set_size_inches(12, 6)\n",
        "\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    # return all the calculated vaules for use later\n",
        "    return roc_auc, fpr, tpr, thresholds"
      ],
      "metadata": {
        "id": "tTPUMv6wnPsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's call this function for both classifiers:"
      ],
      "metadata": {
        "id": "QQ0w97---pBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "auc_NN, fpr_NN, tpr_NN, thresholds_NN = calc_roc(scaled_test_df['target'].values,scaled_test_df['NN_preds'].values, scaled_test_df['totalWeight'].values, \"ROC curve for the neural network classifer\")\n",
        "auc_GDT, fpr_GDT, tpr_GDT, thresholds_GDT = calc_roc(scaled_test_df['target'].values,scaled_test_df['GBT_preds'].values, scaled_test_df['totalWeight'].values, \"ROC curve for the GDT classifer\")"
      ],
      "metadata": {
        "id": "kgVMZ2EDnlve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<font color=\"red\"> TASK </font> : Do either the random forest or the neural network behave better than the random calssification (in dotted lines?) How do you know?\n",
        "\n",
        "<font color=\"red\"> TASK </font> : How much better or worse than random are they?\n",
        "\n",
        "Answers:\n",
        "\n",
        "We can see that both the random forest and the neural network behave better than random classification. However, how much better than random are they? The best way to answer this question is to look at how close each of the ROC curves gets to touching the upper left corner (which represents a perfect classifier with TPR=$1$ and FPR=$0$).\n",
        "\n",
        "<font color=\"red\"> TASK </font> : Although the difference is subtle, which of the two models is closer to this target, showing it is a stronger classifier?"
      ],
      "metadata": {
        "id": "fmOKNSEUIS8v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.1.3: Overfitting + KS test ####"
      ],
      "metadata": {
        "id": "yLuY4wXG4jSs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As supervised machine learning involves training a classifier on example data, you can run into the problem of the **model fitting 'too well'** to the example data, such that it loses generality and will **no longer predict unlabelled data correctly**.\n",
        "\n",
        "We could also consider the case where we train our model on a smaller volume of objects than we test on. This could result in overfitting - the classifier fitting too well to this smaller data set. This makes the model too specific, so that when new objects are introduced, they are misclassified. The diagram below shows this issue:\n",
        "\n",
        "\n",
        "![overfit](https://lh6.googleusercontent.com/8L-Djt0LQTs_gRM9ZpLY4nM3nfbBp9J74osbv5EJjOngdDwu7yPSPBpUQJ_PEuXS7BE=w2400)\n",
        "\n"
      ],
      "metadata": {
        "id": "Jg1WIYO37d2S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can imagine this threshold to be akin to the undestanding how to solve a particular set of questions, and memorising them entirely. At first, you might just get the overall idea but still incorrectly answer the majority of questions (underfitting). With more practice, you may reach a point where you are comfortable with the content and can correctly answer most of the questions (good fitting).\n",
        "\n",
        "Here is where you should stop, congratulate yourself, and move onto another fresh set of practice questions. If you keep practising even further with the **same set**, however, you might memorise the answers and end up not getting a grasp of their reasoning at all (**overfitting**)."
      ],
      "metadata": {
        "id": "2qiJSQT8eeMA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Certain machine learning models are susceptible to overfitting, such as decision trees, but generally, all models can struggle with this. There are many ways to overcome this:\n",
        "* Changing the test/train data ratio or increasing the volume of training data;\n",
        "* Reducing the model complexity by changing their hyperparameters:\n",
        "* * This may be reducing the maximum depth of decision trees in a random forest or increasing the number of trees;\n",
        "* * Or in a neural network this may be reducing the size of your hidden layers;\n",
        "* And generally this may be reducing the number of features in the input data which are used by the ML model. You may think of this as akin to the aphorism, **\"if you go looking for trouble, it will come\"**. More specifically, if too many data features are used, it may be possible for the model to \"spot\" patterns which are not physical, but rather an artifact of the specific data that is used.\n",
        "\n",
        "We can see if our model is overfitting be comparing the response of the $X$ test data and $X$ train data. Ideally, the response to each dataset should be the same, but if these responses are not similar, it is a sign that the classifier has underfitted or overfitted to the training data.\n",
        "\n",
        "</br>\n",
        "\n",
        "We can statistically compare these responses by using the two-sample Kolmogorov–Smirnov test, also known as a **KS test**. This is a **“goodness of fit test”** which compares two distributions and tests if they have the same distribution. We will compare the test data response to the train data response. The KS test returns a metric called the Kolmogorov–Smirnov statistic and a p-value (number describing how likely the test data would have occurred under the null hypothesis of this statistical test). The latter of the two is often easier for drawing conclusions.\n",
        "* Kolmogorov–Smirnov statistic : A metric which assesses the match or mismatch between two distributions by quantifying the distance between them. It assumes the **null hypothesis $H_0$** that they come from the same underlying distribution. Smaller values show stronger agreement.\n",
        "* P-value : the probability that $H_0$ is true; i.e. the test and train responses show the same distribution. Often, a $5\\%$ rule is used. If the p-value is significantly greater than a $0.05$ threshold, our **$H_0$** can be accepted and the **alternative hypothesis $H_1$** can be rejected; i.e. the train and test responses show good agreement rather than severe overfitting.\n",
        "\n",
        "It should be noted the the KS test is not deisgned to work with the binned data of histograms, but it will give us a good apporximation in this example notebook.\n",
        "\n",
        "</br>\n",
        "\n",
        "Let’s now see if our models are overfitted. To do this, we will plot the response of the test data against the train data. Let's program a function to do just that:"
      ],
      "metadata": {
        "id": "Bs09Kp4_pHYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the needed module to preform a Kolmogorov–Smirnov test (ks test)\n",
        "from scipy.stats import ks_2samp\n",
        "\n",
        "\n",
        "def plot_overfittingCheck(Title,\n",
        "                          df_train, df_test, preds,\n",
        "                          n_bins, test_size=0.33, log=False):\n",
        "    \"\"\"\n",
        "    This funtion plots the overfitting check plots, while also returning the results\n",
        "    of a Kolmogorov–Smirnov test comparing the test data response and train data response\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    sig_train = df_train[df_train['target']==1]\n",
        "    bkg_train = df_train[df_train['target']==0]\n",
        "    sig_test = df_test[df_test['target']==1]\n",
        "    bkg_test = df_test[df_test['target']==0]\n",
        "\n",
        "    sig_train_weights = sig_train['totalWeight'].values\n",
        "    bkg_train_weights = bkg_train['totalWeight'].values\n",
        "    sig_test_weights = sig_test['totalWeight'].values\n",
        "    bkg_test_weights = bkg_test['totalWeight'].values\n",
        "\n",
        "    # get the predictions (in form of probabilities) for background and\n",
        "    # signal for the train data set and the test data set\n",
        "    sig_train_prob = sig_train[preds].values\n",
        "    bkg_train_prob = bkg_train[preds].values\n",
        "    sig_test_prob = sig_test[preds].values\n",
        "    bkg_test_prob = bkg_test[preds].values\n",
        "\n",
        "    # find min and max for plot\n",
        "    d_min = min(sig_train_prob.min(), bkg_train_prob.min())\n",
        "    d_max = max(sig_train_prob.max(), bkg_train_prob.max())\n",
        "\n",
        "    # plot the background response of the train data set (make orange and translucent)\n",
        "    bkg_tr, bins, _ = plt.hist(bkg_train_prob,\n",
        "                               bins=n_bins,\n",
        "                               range=(d_min,d_max),\n",
        "                               color='tab:blue',\n",
        "                               label='bkg train',\n",
        "                               alpha=0.4,\n",
        "                               weights = bkg_train_weights/(1-test_size),\n",
        "                               log = log,\n",
        "                               histtype=\"stepfilled\",\n",
        "                               edgecolor='tab:blue',\n",
        "                               linewidth=5)\n",
        "\n",
        "    # plot the signal response of the train data set (make blue and translucent)\n",
        "    sig_tr, bins, _ = plt.hist(sig_train_prob,\n",
        "                              bins=n_bins,\n",
        "                              range=(d_min,d_max),\n",
        "                              color='tab:orange',\n",
        "                              label='sig train',\n",
        "                              alpha=0.4,\n",
        "                              weights = sig_train_weights/(1-test_size),\n",
        "                              log = log,\n",
        "                              histtype=\"stepfilled\",\n",
        "                              edgecolor='tab:orange',\n",
        "                              linewidth=5)\n",
        "\n",
        "\n",
        "\n",
        "    # find bin centres\n",
        "    bin_centers = (bins[:-1] + bins[1:])/2\n",
        "    # use numpy histograms to find heights of histogram bars for the test data set\n",
        "    sig_te, _ = np.histogram(sig_test_prob, bins = bins, weights = sig_test_weights/test_size)\n",
        "    bkg_te, _ = np.histogram(bkg_test_prob, bins = bins, weights = bkg_test_weights/test_size)\n",
        "\n",
        "    # plot the test background and signal histograms as points\n",
        "    plt.plot(bin_centers,bkg_te, 'o', c = 'tab:blue', label = 'bkg test', alpha = 0.9, markeredgecolor = 'k')\n",
        "    plt.plot(bin_centers,sig_te, 'o', c = 'tab:orange', label = 'sig test', alpha = 0.9, markeredgecolor = 'k')\n",
        "\n",
        "    # set up the plot\n",
        "    plt.title(Title)\n",
        "    plt.xlabel(\"Response (0 = background, 1 = signal)\")\n",
        "    plt.ylabel(\"Normalised frequency\")\n",
        "    if log:\n",
        "      plt.yscale(\"log\")\n",
        "    plt.legend()\n",
        "\n",
        "    fig = plt.gcf()\n",
        "    fig.set_size_inches(12, 6)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    # return the Kolmogorov–Smirnov test results\n",
        "    return ks_2samp(sig_tr, sig_te),ks_2samp(bkg_tr,bkg_te)"
      ],
      "metadata": {
        "id": "6UUL_Aksn1Wx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It may be worth highlighting that the test and training data are different sizes based on the way how the Monte Carlo data were split in Section 3. This is important since the height of a histogram bar in the training data plots would be expected to be smaller than the height of a test data histogram bar. To get around this and to allow us to make visual bin-by-bin comparisons between the test and training data, the function **rescales** both the test and training data to have the same total frequency.\n",
        "\n",
        "Let’s call this function now for the random forest:"
      ],
      "metadata": {
        "id": "li4GQZad-2kV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ksTest_GBT_sig, ksTest_GBT_bkg = plot_overfittingCheck(\"GBT overfitting check\", scaled_train_df, scaled_test_df, 'GBT_preds', BINS, log=True)"
      ],
      "metadata": {
        "id": "8NGoiIhVp2GO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The KS results for the signal are:  \\n\", ksTest_GBT_sig)\n",
        "print(\"The KS results for the background are:  \\n\", ksTest_GBT_bkg)"
      ],
      "metadata": {
        "id": "zYhm1nPz-__v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And the same for the neural network:"
      ],
      "metadata": {
        "id": "-wZ9LqYt_E_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ksTest_NN_sig, ksTest_NN_bkg = plot_overfittingCheck(\"NN overfitting check\", scaled_train_df, scaled_test_df, 'NN_preds', BINS, log=True)\n",
        "print(ksTest_NN_sig)\n",
        "print(ksTest_NN_bkg)"
      ],
      "metadata": {
        "id": "LHg3QjCP_EG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now consider our results which do show similar behaviour between the random forest and the neural network.\n",
        "\n",
        "What do the p-values tell us about the agreement between the training and testing responses?\n",
        "\n",
        "In reality we would want to look at the hyperparameters of the model, and in an ideal world have more data. But even with these issues, it is still performing at a resonable level.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "x1I_GvLNrA6U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2: Results of the Machine Learning Method ###"
      ],
      "metadata": {
        "id": "fjUMLmlL7oQn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So far we have obtained and processed our data to be classified by two machine learning models - our neural network and our random forest. These have been trained on a subset of the Monte Carlo data while an independent subset has been used to test how well our trained classifiers work when faced with unseen data. We then met a few metrics which help us to evaluate the quality of our models.\n",
        "\n",
        "</br>\n",
        "\n",
        "However, now is where we begin to answer the question of how our powerful tools can be applied to the task of finding dark matter. In this section, we evaluate how well our signal is selected in and amongst background with in terms of the signal **significance**."
      ],
      "metadata": {
        "id": "oy7rpdqtfRHd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.2.1: Finding the significance ####"
      ],
      "metadata": {
        "id": "_ifaNlpOxTID"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Putting all the data into a classifier means we only have one variable to optimise (the classifier response), unlike in notebook 2 where there are many. Using the classifier output also achieves higher significance values than using individual variables because machine learning models can find complex correlations in many dimensions.\n",
        "\n",
        "We will now find the significance of the signal by doing something called a 'scan cut' on the classifier response. If we look at the response plot and imagine a vertical line on it, we can perform a cut on the response - keeping everything to the right, and using the same significance equation as we used in notebook 2:\n",
        "\n",
        "$ \\text{significance} = \\frac{\\text{signal}}{\\sqrt{\\text{background}}} $\n",
        "\n",
        "Where “signal\" and \"background” in this equation are each the sum of all the weights of the signal or background events in the included part of the histogram (to the right of the line in the diagram below) like we did and programmed in notebook 2.\n",
        "\n",
        "![sigcaldia](https://lh3.googleusercontent.com/Dzh5AjymVFfv7Fs8_NF27sxKfcIukVsR8DNkn3lzS49aBRvBvBQ_2EjCw_iWll8hwK4=w2400)\n",
        "\n",
        "\n",
        "We shall move this line from left to right, performing scan cutting and getting a significance value for each place we perform the cut. In turn, this can create a line plot of the significance over all of the cuts.\n",
        "\n",
        "The code to do this can be seen below (note that NumPy masks are used to select the data from the histogram, see more on this [here]( https://www.google.com/search?client=opera-gx&q=in+unison&sourceid=opera&ie=UTF-8&oe=UTF-8)):"
      ],
      "metadata": {
        "id": "bCY4C9aX7wMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title run this cell before the below one\n",
        "\n",
        "def plot_response_alt(fig,Title,df,preds,n_bins,index,xAxis,Log):\n",
        "    \"\"\"\n",
        "    This function plots the response of a classifer on signal and background\n",
        "    Monte Carlo events\n",
        "\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    fig : TYPE\n",
        "        DESCRIPTION.\n",
        "    clf : TYPE\n",
        "        DESCRIPTION.\n",
        "    Title : TYPE\n",
        "        DESCRIPTION.\n",
        "    sig : TYPE\n",
        "        DESCRIPTION.\n",
        "    sig_weights : TYPE\n",
        "        DESCRIPTION.\n",
        "    bkg : TYPE\n",
        "        DESCRIPTION.\n",
        "    bkg_weights : TYPE\n",
        "        DESCRIPTION.\n",
        "    n_bins : TYPE\n",
        "        DESCRIPTION.\n",
        "    index : TYPE\n",
        "        DESCRIPTION.\n",
        "    xAxis : TYPE\n",
        "        DESCRIPTION.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    None.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Add this axes to the fig at index\n",
        "    ax = fig.add_subplot(index)\n",
        "\n",
        "    sig = df[df['target']==1]\n",
        "    bkg = df[df['target']==0]\n",
        "\n",
        "    # Get response (in form of probabilities) of signal and background\n",
        "    sig_prob = sig[preds].values\n",
        "    bkg_prob = bkg[preds].values\n",
        "\n",
        "    sig_weights = sig['totalWeight'].values\n",
        "    bkg_weights = bkg['totalWeight'].values\n",
        "\n",
        "    # find min and max for plot\n",
        "    d_min = min(sig_prob.min(), bkg_prob.min())\n",
        "    d_max = max(sig_prob.max(), bkg_prob.max())\n",
        "\n",
        "    # plot background response (make orange and translucent)\n",
        "    ax.hist(bkg_prob,\n",
        "             bins = n_bins,\n",
        "             range = (d_min,d_max),\n",
        "             color = 'tab:blue',\n",
        "             label = 'bkg test',\n",
        "             alpha = 0.4,\n",
        "             density = False,\n",
        "             weights = bkg_weights,\n",
        "             log = Log,\n",
        "             histtype=\"stepfilled\",\n",
        "             edgecolor='tab:blue',\n",
        "             linewidth=5)\n",
        "\n",
        "    # plot signal response (make blue and translucent)\n",
        "    ax.hist(sig_prob,\n",
        "             bins = n_bins,\n",
        "             range = (d_min,d_max),\n",
        "             color = 'tab:orange',\n",
        "             label = 'sig test',\n",
        "             alpha = 0.4,\n",
        "             density = False,\n",
        "             weights = sig_weights,\n",
        "             log = Log,\n",
        "             histtype=\"stepfilled\",\n",
        "             edgecolor='tab:orange',\n",
        "             linewidth=5)\n",
        "\n",
        "    # Set up plot\n",
        "    if Title != None:\n",
        "        ax.set_title(Title)\n",
        "    ax.set_xlabel(\"Response (0 = background, 1 = signal)\")\n",
        "    ax.set_ylabel(\"Frequency\")\n",
        "    ax.legend()\n",
        "    if not xAxis:\n",
        "        ax.xaxis.set_visible(False)\n",
        "\n",
        "    return"
      ],
      "metadata": {
        "cellView": "form",
        "id": "dLN8tmAYqO_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define simpler equation to find the approximate median significance (approximation\n",
        "# that background count is much larger than the signal)\n",
        "def AMS_short(tpr, fpr, b_reg):\n",
        "    return tpr/np.power(fpr+b_reg, 0.5)\n",
        "\n",
        "\n",
        "# Plot significance from scan cutting\n",
        "def plot_significance(Title,df,preds,log=False,oversample_frac=1.0,npoints=24):\n",
        "    \"\"\"\n",
        "    This function calculates the significance of the signal using the response\n",
        "    of the classifer\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    Title : TYPE\n",
        "        DESCRIPTION.\n",
        "    clf : TYPE\n",
        "        DESCRIPTION.\n",
        "    X_test : TYPE\n",
        "        DESCRIPTION.\n",
        "    X_test_weight : TYPE\n",
        "        DESCRIPTION.\n",
        "    X_test_ID : TYPE\n",
        "        DESCRIPTION.\n",
        "    sig_test : TYPE\n",
        "        DESCRIPTION.\n",
        "    sig_test_W : TYPE\n",
        "        DESCRIPTION.\n",
        "    bkg_test : TYPE\n",
        "        DESCRIPTION.\n",
        "    bkg_test_W : TYPE\n",
        "        DESCRIPTION.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    sigs : TYPE\n",
        "        DESCRIPTION.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    fig, ax = plt.subplots(2,1,sharex=True)\n",
        "    #fig.tight_layout()\n",
        "    [axi.set_axis_off() for axi in ax.ravel()]\n",
        "    # array to hold significance vaules\n",
        "    sigs = []\n",
        "\n",
        "    # get the predictions (in form of probabilities)\n",
        "    probs = df[preds].values\n",
        "\n",
        "    # make an array of prediction vaules to scan over\n",
        "    prob_space = np.linspace(0,max(probs),npoints)\n",
        "\n",
        "\n",
        "    #loop through prediction vaules\n",
        "    for p in prob_space:\n",
        "\n",
        "        # generate masks to find events that correspond to the following conditions:\n",
        "        prob_mask = (probs > p)\n",
        "\n",
        "        # get the weights of the signal and background events that have a response\n",
        "        # less than the current cutting vaule (p from prob_space)\n",
        "        sig_weights = df[(df['target']==1) & (df[preds]>p)]['totalWeight']\n",
        "        bkg_weights = df[(df['target']==0) & (df[preds]>p)]['totalWeight']\n",
        "\n",
        "        # Get number of signal and number of background events that have a response\n",
        "        # less than the current cutting vaule (p from prob_space)\n",
        "        signal_selected_num = len(df[(df['target']==1) & (df[preds]>p)])\n",
        "        background_selected_num = len(df[(df['target']==0) & (df[preds]>p)])\n",
        "\n",
        "        # Find the sum of the weights found earlier\n",
        "        signal_weights_selected = np.sum(sig_weights)/oversample_frac\n",
        "        background_weights_selected =np.sum(bkg_weights)\n",
        "\n",
        "        # Calculate the significace, but if one of the weights sums to zero set sig to zero\n",
        "        if (background_weights_selected == 0.0 or signal_weights_selected == 0.0): # Avoid errors\n",
        "            significance = 0\n",
        "        else:\n",
        "            significance = AMS_short(signal_weights_selected, background_weights_selected,0.001)\n",
        "\n",
        "        #append found significance vaule\n",
        "        sigs.append(significance)\n",
        "\n",
        "\n",
        "    # Add First plot\n",
        "    ax = fig.add_subplot(212)\n",
        "    ax.yaxis.tick_right()\n",
        "    # plot significance curve from scan cutting\n",
        "    ax.plot(prob_space, sigs)\n",
        "\n",
        "    # Set up plot\n",
        "    ax.set_xlabel(\"Response of classifer\")\n",
        "    ax.set_ylabel(\"Significance, $\\sigma$\")\n",
        "\n",
        "    # We will add a second plot of the reponce histogram above the significace plot\n",
        "    plot_response_alt(fig,\n",
        "                      Title,\n",
        "                      df,\n",
        "                      preds,\n",
        "                      BINS,\n",
        "                      211,\n",
        "                      False,\n",
        "                      log)\n",
        "\n",
        "    # Adjust spacing of the two plots on the same figure\n",
        "    plt.subplots_adjust(wspace=0, hspace=0)\n",
        "    fig.set_size_inches(12, 6)\n",
        "    plt.show()\n",
        "\n",
        "    return sigs"
      ],
      "metadata": {
        "id": "FTivBS08rXm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's call this function for the neural network:"
      ],
      "metadata": {
        "id": "CAPyFDVq_d-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "significance_NN = plot_significance(\"Significance from the neural network classifier\",scaled_test_df,'NN_preds',log=True,oversample_frac=oversample_rate+1.0)"
      ],
      "metadata": {
        "id": "i9AACZojs7bL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And again for the random forest:"
      ],
      "metadata": {
        "id": "icdERTG6_gn8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "significance_GBT = plot_significance(\"Significance from the GBT classifier\",scaled_test_df,'GBT_preds',log=True,oversample_frac=oversample_rate+1.0)"
      ],
      "metadata": {
        "id": "JbrNPKD2_h8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s now find the highest significance for the signal (the dark matter signal) for each classifier. Notice that we are adjusting for the oversampling otherwise our significance would be artificially hight.\n",
        "\n",
        "**This is the final result of your analysis!!!**"
      ],
      "metadata": {
        "id": "44KTuYgr_qKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print max significances found for each classifer\n",
        "print(\"NN significance: \",max(significance_NN),\"    With KS test results: \",ksTest_NN_sig)\n",
        "print(\"GDT significance: \",max(significance_GBT),\"    With KS test results: \",ksTest_GBT_sig)"
      ],
      "metadata": {
        "id": "lpLPtwDf_sea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "</br>\n",
        "\n",
        "Let's now take a moment to round off our evaluation of our two models:\n",
        "\n",
        "* **Neural network:**  The neural network looks like it can be used to obtain a sample with a DM signal significance of $1.12\\sigma$. This is a long way from the $3 \\sigma$ gold standard, but much of that is down to the dataset we're using. In order to run run the above code in a reasonable time, we have used small files. Since DM singal is rare at the best of times, it is no surpirse that significance is low here.\n",
        "\n",
        "* **Random forest:** The signal significance from this model is a bit higher than the neural network at $1.41\\sigma$! Though it seems that there is an issues maybe to do with the small number of events in the final bins which are making these results a bit overly optimistic.\n",
        "\n",
        "Despite the significance being low here, compared to results from using cut-based optimisation, in reality machine learning models show great promise in getting us over the $3\\sigma$ threshold in our search to find Dark Matter, and is a a very active topic of research around the world.\n",
        "\n",
        "**Well done you have completed the analysis!! What do you want to improve? Its hard to find dark matter - in the end we need more data from the ATLAS experiment in order to discover rare events!!!**"
      ],
      "metadata": {
        "id": "ui-qDMaLlfNJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.2.2: Train your own classifier ####\n",
        "\n",
        "**Skip this last Advanced section**\n",
        "\n",
        "Now it is time to train your own classifier using everything you have learnt, you shouldn't have to do anything which you haven't seen before in this notebook so use this as a chance to consolidate your knowledge so far. Feel free to look back through the notebook if you are unsure on what to do."
      ],
      "metadata": {
        "id": "HGEdwfcTljE_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 1: Pre processing ####"
      ],
      "metadata": {
        "id": "yXO_hMWNMOuv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the premade dataframes perform the train test split.\n",
        "Initialise the classifier with the machine learning method of your choice (Neural Network, Random Forest or [other](https://www.google.com)) using your starting hyperparameters."
      ],
      "metadata": {
        "id": "zYdLHdtuMWwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Write your code in in this cell"
      ],
      "metadata": {
        "id": "I43tV0_9N4-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 2: Train the classifier ####"
      ],
      "metadata": {
        "id": "dZzYfkjhMd7g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now train your classifer, this is a simple step where you fit the"
      ],
      "metadata": {
        "id": "zs_mbHMXMhZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Write your code in in this cell"
      ],
      "metadata": {
        "id": "UhHSZfXKN_7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 3: Analyse the classifier ####"
      ],
      "metadata": {
        "id": "SwrorxniMog5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Analyse your classifier using the prewritten functions."
      ],
      "metadata": {
        "id": "KVTiqpGyMri8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Write your code in in this cell"
      ],
      "metadata": {
        "id": "JH4wigSMOFa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### plot_response() #####"
      ],
      "metadata": {
        "id": "u5tqTS9zK_mf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**df** → the dataframe containing the predictions\n",
        "\n",
        "**Title** → title of your plot\n",
        "\n",
        "**preds** → name of the column of the predictions to assess\n",
        "\n",
        "**n_bins** → number of bins to plot histogram with\n",
        "\n",
        "**Log** → boolean to get y-axis to be logarithmic scale\n"
      ],
      "metadata": {
        "id": "DERz6SokLKfS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### calc_roc() #####"
      ],
      "metadata": {
        "id": "1n0SYHxbLdg_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**y** → targets\n",
        "\n",
        "**y_pred** → predictions\n",
        "\n",
        "**weights** → sample weights\n",
        "             \n",
        "**Title** → title of your plot"
      ],
      "metadata": {
        "id": "sN3u1-XfLlEA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### plot_overfittingCheck() #####"
      ],
      "metadata": {
        "id": "PByfguajLvvb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Title** → title of your plot                    \n",
        "\n",
        "**df_train** → training dataframe containing the predictions\n",
        "\n",
        "**df_test** → testing dataframe containing the predictions\n",
        "\n",
        "**preds** → name of the column of the predictions to assess\n",
        "\n",
        "**n_bins** → number of bins to plot histogram with\n",
        "\n",
        "**test_size** → fraction of events in test\n",
        "\n",
        "**log** → boolean to get y-axis to be logarithmic scale"
      ],
      "metadata": {
        "id": "94KHUc-ZL07m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 4: Retrain ####"
      ],
      "metadata": {
        "id": "qnvFuZEQMy9z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retrain your classifier if it does not meet your standards then re-analyse your classifier."
      ],
      "metadata": {
        "id": "Rzioj8V9M3oL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Write your code in in this cell"
      ],
      "metadata": {
        "id": "pjgEBkCYOGae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 5: Calculate the significance ####"
      ],
      "metadata": {
        "id": "4GC_w_18NAoq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now calculate the significance of the signal using the prewritten function"
      ],
      "metadata": {
        "id": "4spvN9MWNHDv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Write your code in in this cell"
      ],
      "metadata": {
        "id": "qA9Ew0m7OMBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### plot_significance() #####"
      ],
      "metadata": {
        "id": "9w_bGso9Ncyv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Title** → title of your plot\n",
        "\n",
        "**df** → dataframe containing the predictions\n",
        "\n",
        "**preds** → name of the column of the predictions to assess\n",
        "\n",
        "**log** → boolean to get y-axis to be logarithmic scale\n",
        "\n",
        "**oversample_frac** → size of oversampled signal compared to original signal to correct significance"
      ],
      "metadata": {
        "id": "dr6ZKXofNg3G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Section 5 quiz ###"
      ],
      "metadata": {
        "id": "dCxp9oCzmv_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "print(\"Often when developing machine learning models, there is a trade-off between maximising the \\n\"+\n",
        "      \"TPR and minimising the FPR. If you are attempting to find a really clear signal, but are \\n\"+\n",
        "      \"confident that you have enough data to discard if need be, which of the two are you most concerned with?\")\n",
        "out = widgets.Dropdown(options=[('',0),('Maximising TPR',1),\n",
        "                                ('Minimising FPR',0)],description='Answer:',disabled=False)\n",
        "def drop_check(guess):\n",
        "  if guess==1:\n",
        "    print(\"\\033[1;32;47m Correct!  \\n\")\n",
        "  else:\n",
        "    print(\"\\033[1;32;47m Incorrect.  \\n\")\n",
        "check = widgets.interactive_output(drop_check,{'guess':out})\n",
        "widgets.HBox([out,check])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "3rFaM9RCsiES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "print(f\"In principle, it is possible to perform goodness of fit tests using several different methods, \\n\"+\n",
        "      \"dependent upon the situation. One example of a test which is often used in physics is the \\nchi-squared\"+\n",
        "      \" test. Let\\'s say we wish to compare the fits in the results from two different analyses -\\n\"+\n",
        "      \"one using \"+\n",
        "      \"the chi-squared and another using the KS-test. Which metric do we want to use?\")\n",
        "out = widgets.Dropdown(options=[('',0),('Significance',0),\n",
        "                                ('KS statistic',0), (\"The p-value\",1)],description='Answer:',disabled=False)\n",
        "def drop_check(guess):\n",
        "  if guess==1:\n",
        "    print(\"\\033[1;32;47m Correct!  \\n\")\n",
        "  else:\n",
        "    print(\"\\033[1;32;47m Incorrect.  \\n\")\n",
        "check = widgets.interactive_output(drop_check,{'guess':out})\n",
        "widgets.HBox([out,check])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "a7BdtrgDsj2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "print(\"In one analysis (A), results are found to match a null hypothesis with a p-value of 90%. \\n\"+\n",
        "      \"In another analysis (B), results match the same hypothesis with a p-value of 10%. \\n\"+\n",
        "      \"Which experiment shows stronger agreement with the null hypothesis?\")\n",
        "out = widgets.Dropdown(options=[('',0),('A',1),\n",
        "                                ('B',0)],description='Answer:',disabled=False)\n",
        "def drop_check(guess):\n",
        "  if guess==1:\n",
        "    print(\"\\033[1;32;47m Correct!  \\n\")\n",
        "  else:\n",
        "    print(\"\\033[1;32;47m Incorrect.  \\n\")\n",
        "check = widgets.interactive_output(drop_check,{'guess':out})\n",
        "widgets.HBox([out,check])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "L07EhPd8skFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Q\n",
        "print(\"In the above analysis which we did, which machine learning model demonstrated stronger evidence of overfitting?\")\n",
        "out = widgets.Dropdown(options=[('',0),('Random forest',0),\n",
        "                                ('Neural network',1)],description='Answer:',disabled=False)\n",
        "def drop_check(guess):\n",
        "  if guess==1:\n",
        "    print(\"\\033[1;32;47m Correct!  \\n\")\n",
        "  else:\n",
        "    print(\"\\033[1;32;47m Incorrect.  \\n\")\n",
        "check = widgets.interactive_output(drop_check,{'guess':out})\n",
        "widgets.HBox([out,check])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "AjDLBWr6skRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  Last Question\n",
        "print(\"In the same analysis, which machine learning model demonstrated evidence of finding a greater signal significance?\")\n",
        "out = widgets.Dropdown(options=[('',0),('Random forest',0),\n",
        "                                ('Neural network',1)],description='Answer:',disabled=False)\n",
        "def drop_check(guess):\n",
        "  if guess==1:\n",
        "    print(\"\\033[1;32;47m Correct!  \\n\")\n",
        "  else:\n",
        "    print(\"\\033[1;32;47m Incorrect.  \\n\")\n",
        "check = widgets.interactive_output(drop_check,{'guess':out})\n",
        "widgets.HBox([out,check])"
      ],
      "metadata": {
        "id": "jgbZqOl4skf6",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6: Conclusion ##\n",
        "Congratulations on completing the notebook!!!\n",
        "\n",
        "This notebook describes how to use machine learning to find dark matter within the ATLAS open  data project, working on supervised learning. This is when we train a machine learning model with example data of what we are looking for then the program will perform a task (find dark matter production process)."
      ],
      "metadata": {
        "id": "3L_Bzt_9RE2_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##7: Now for something completely different!##\n",
        "\n",
        "Now let's try starting again but with a completely different dataset.\n",
        "\n",
        "There are some thing below to get you started but **it's over to you!**"
      ],
      "metadata": {
        "id": "SnK687XyDa9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "X, y = datasets.load_iris(return_X_y=True, as_frame=True)"
      ],
      "metadata": {
        "id": "yqxcsFxor5Qm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(datasets.load_iris()['DESCR'])"
      ],
      "metadata": {
        "id": "pLvxOYr1sTjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.describe()"
      ],
      "metadata": {
        "id": "C0hOwIDmsxCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.info()"
      ],
      "metadata": {
        "id": "rMnx1hl2s4hE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iOo47zhjES4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8: Credits and licencing  ##\n",
        "\n",
        "Project Lead: \t\tKate Shaw\n",
        "<br>\n",
        "<br>\n",
        "Project Supervisors: \tMeirin Oan Evans, Zöe Earnshaw, Thomas Stevenson, Caley Yardley\n",
        "<br>\n",
        "<br>\n",
        "Developers: \t\tChristopher Comiskey-Erazo, Iago Rosetto, Oscar Jackson"
      ],
      "metadata": {
        "id": "jco0MPH-6f3U"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x3V9N2wKDwTW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
